{
  "generatedAt": "2025-11-18T12:09:40.028Z",
  "model": "gpt-5",
  "profile": "balanced",
  "threshold": 65,
  "totalAnalyzed": 100,
  "totalPublished": 12,
  "publishTarget": "default",
  "debug": {
    "analysisFailed": true,
    "usedLLM": false,
    "useOpenAIEnv": false,
    "hasOpenAIKey": false,
    "minPublish": 12,
    "weightsUsed": {
      "research": 35,
      "policy": 35,
      "institution": 15,
      "impact": 15
    },
    "labelsUsed": {
      "research": "Recherche",
      "policy": "Politiques",
      "institution": "Institution",
      "impact": "Impact"
    },
    "descUsed": {
      "research": "articles/journaux, conférences, CFP, résultats scientifiques",
      "policy": "lois, régulations, standards, cadres, gouvernance",
      "institution": "communiqués des grandes agences et autorités (UNESCO, OCDE, CNIL, ministères…)",
      "impact": "impact direct pour la classe/enseignants/universités/EdTech"
    },
    "keysUsed": {
      "research": [
        "arxiv",
        "preprint",
        "doi",
        "journal",
        "conference",
        "proceedings",
        "workshop",
        "submission",
        "cfp",
        "acceptance",
        "springer",
        "wiley",
        "nature",
        "frontiers",
        "acm",
        "ieee"
      ],
      "policy": [
        "ai act",
        "regulation",
        "régulation",
        "policy",
        "politique",
        "standard",
        "framework",
        "guidance",
        "law",
        "act",
        "ordonnance",
        "décret",
        "ethics",
        "ethical"
      ],
      "institution": [
        "unesco",
        "oecd",
        "ocde",
        "cnil",
        "edps",
        "ncsc",
        "minist",
        "commission",
        "nsf",
        "ukri",
        "ies",
        "european commission"
      ],
      "impact": [
        "school",
        "education",
        "teacher",
        "enseignant",
        "k-12",
        "universit",
        "student",
        "pupil",
        "mooc",
        "classroom",
        "edtech"
      ]
    }
  },
  "items": [
    {
      "title": "ST-ProC: A Graph-Prototypical Framework for Robust Semi-Supervised Travel Mode Identification",
      "url": "https://arxiv.org/abs/2511.13702v1",
      "source": "arXiv – cs.LG + learning analytics",
      "published": "2025-11-17T18:52:11.000Z",
      "score": 70,
      "resume_fr": "Travel mode identification (TMI) from GPS trajectories is critical for urban intelligence, but is hampered by the high cost of annotation, leading to severe label scarcity. Prevailing semi-supervised learning (SSL) methods are ill-suited for this task, as they suffer from catastrophic confirmation bias and ignore the intrinsic data manifold. We propose ST-ProC, a novel graph-prototypical multi-objective SSL framework to address these limitations. Our framework synergizes a graph-prototypical core with foundational SSL Support. The core exploits the data manifold via graph regularization, proto",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Making Evidence Actionable in Adaptive Learning Closing the Diagnostic Pedagogical Loop",
      "url": "https://arxiv.org/abs/2511.13542v1",
      "source": "arXiv – cs.AI + education/MOOC",
      "published": "2025-11-17T16:15:50.000Z",
      "score": 85,
      "resume_fr": "Adaptive learning often diagnoses precisely yet intervenes weakly, producing help that is mistimed or misaligned. This study presents evidence supporting an instructor-governed feedback loop that converts concept-level assessment evidence into vetted microinterventions. The adaptive learning algorithm includes three safeguards: adequacy as a hard guarantee of gap closure, attention as a budgeted limit for time and redundancy, and diversity as protection against overfitting to a single resource. We formulate intervention assignment as a binary integer program with constraints for coverage, time",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "The Quick Red Fox gets the best Data Driven Classroom Interviews: A manual for an interview app and its associated methodology",
      "url": "https://arxiv.org/abs/2511.13466v1",
      "source": "arXiv – cs.HC + education",
      "published": "2025-11-17T15:08:47.000Z",
      "score": 50,
      "resume_fr": "Data Driven Classroom Interviews (DDCIs) are an interviewing technique that is facilitated by recent technological developments in the learning analytics community. DDCIs are short, targeted interviews that allow researchers to contextualize students' interactions with a digital learning environment (e.g., intelligent tutoring systems or educational games) while minimizing the amount of time that the researcher interrupts that learning experience, and focusing researcher time on the events they most want to focus on DDCIs are facilitated by a research tool called the Quick Red Fox (QRF)--an op",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Examining the Usage of Generative AI Models in Student Learning Activities for Software Programming",
      "url": "https://arxiv.org/abs/2511.13271v1",
      "source": "arXiv – cs.AI + education/MOOC",
      "published": "2025-11-17T11:42:24.000Z",
      "score": 100,
      "resume_fr": "The rise of Generative AI (GenAI) tools like ChatGPT has created new opportunities and challenges for computing education. Existing research has primarily focused on GenAI's ability to complete educational tasks and its impact on student performance, often overlooking its effects on knowledge gains. In this study, we investigate how GenAI assistance compares to conventional online resources in supporting knowledge gains across different proficiency levels. We conducted a controlled user experiment with 24 undergraduate students of two different levels of programming experience (beginner, inter",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 15,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=15, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "SynthGuard: An Open Platform for Detecting AI-Generated Multimedia with Multimodal LLMs",
      "url": "https://arxiv.org/abs/2511.12404v1",
      "source": "arXiv – cs.AI + education/MOOC",
      "published": "2025-11-16T00:50:24.000Z",
      "score": 50,
      "resume_fr": "Artificial Intelligence (AI) has made it possible for anyone to create images, audio, and video with unprecedented ease, enriching education, communication, and creative expression. At the same time, the rapid rise of AI-generated media has introduced serious risks, including misinformation, identity misuse, and the erosion of public trust as synthetic content becomes increasingly indistinguishable from real media. Although deepfake detection has advanced, many existing tools remain closed-source, limited in modality, or lacking transparency and educational value, making it difficult for users",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Students Compete—and Cooperate—in FIRST Global Robotics Challenge",
      "url": "https://spectrum.ieee.org/first-global-robotics-challenge",
      "source": "IEEE Spectrum – AI",
      "published": "2025-11-15T14:00:02.000Z",
      "score": 50,
      "resume_fr": "Aspiring engineers from 191 countries gathered in Panama City in October to compete in the FIRST Global Robotics Challenge. The annual contest aims to foster problem-solving, cooperation, and inspire the next generation of engineers through three challenges that are inspired by a different theme every year. Teams of students from 14 to 18 years old from around the world compete in the three day event, remotely operating their robots to complete the challenges. This year’s topic was “Eco-equilibrium,” emphasizing the importance of preserving ecosystems and protecting vulnerable species. Turning",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=0, Impact=15.",
      "image": "https://spectrum.ieee.org/media-library/image.jpg?id=62186165&width=1200&height=600&coordinates=0%2C232%2C0%2C232"
    },
    {
      "title": "CollaClassroom: An AI-Augmented Collaborative Learning Platform with LLM Support in the Context of Bangladeshi University Students",
      "url": "https://arxiv.org/abs/2511.11823v1",
      "source": "arXiv – cs.HC + education",
      "published": "2025-11-14T19:23:42.000Z",
      "score": 50,
      "resume_fr": "CollaClassroom is an AI-enhanced platform that embeds large language models (LLMs) into both individual and group study panels to support real-time collaboration. We evaluate CollaClassroom with Bangladeshi university students (N = 12) through a small-group study session and a pre-post survey. Participants have substantial prior experience with collaborative learning and LLMs and express strong receptivity to LLM-assisted study (92% agree/strongly agree). Usability ratings are positive, including high learnability(67% \"easy\"), strong reliability (83% \"reliable\"), and low frustration (83% \"not ",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Differences in the Moral Foundations of Large Language Models",
      "url": "https://arxiv.org/abs/2511.11790v1",
      "source": "arXiv – cs.AI + education/MOOC",
      "published": "2025-11-14T18:21:22.000Z",
      "score": 50,
      "resume_fr": "Large language models are increasingly being used in critical domains of politics, business, and education, but the nature of their normative ethical judgment remains opaque. Alignment research has, to date, not sufficiently utilized perspectives and insights from the field of moral psychology to inform training and evaluation of frontier models. I perform a synthetic experiment on a wide range of models from most major model providers using Jonathan Haidt's influential moral foundations theory (MFT) to elicit diverse value judgments from LLMs. Using multiple descriptive statistical approaches",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Exploring The Interaction-Outcome Paradox: Seemingly Richer and More Self-Aware Interactions with LLMs May Not Yet Lead to Better Learning",
      "url": "https://arxiv.org/abs/2511.09458v1",
      "source": "arXiv – cs.HC + education",
      "published": "2025-11-12T16:18:36.000Z",
      "score": 85,
      "resume_fr": "While Large Language Models (LLMs) have transformed the user interface for learning, moving from keyword search to natural language dialogue, their impact on educational outcomes remains unclear. We present a controlled study (N=20) that directly compares the learning interaction and outcomes between LLM and search-based interfaces. We found that although LLMs elicit richer and nuanced interactions from a learner, they do not produce broadly better learning outcomes. In this paper, we explore this the ``Interaction-Outcome Paradox.'' To explain this, we discuss the concept of a cognitive shift",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Densing law of LLMs",
      "url": "https://www.nature.com/articles/s42256-025-01137-0",
      "source": "Nature Machine Intelligence",
      "published": "2025-11-06T00:00:00.000Z",
      "score": 70,
      "resume_fr": "",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=0.",
      "image": "https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fs42256-025-01137-0/MediaObjects/42256_2025_1137_Fig1_HTML.png"
    },
    {
      "title": "Interpersonal neural synchronization underlies interactive concept learning in older adults",
      "url": "https://www.nature.com/articles/s41539-025-00368-5",
      "source": "npj Science of Learning (Nature)",
      "published": "2025-10-31T00:00:00.000Z",
      "score": 85,
      "resume_fr": "",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 15,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=15, Impact=0.",
      "image": "https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fs41539-025-00368-5/MediaObjects/41539_2025_368_Fig1_HTML.png"
    },
    {
      "title": "How to avoid three common pitfalls in EdTech impact evaluations",
      "url": "https://world-education-blog.org/2025/10/17/how-to-avoid-three-common-pitfalls-in-edtech-impact-evaluations/",
      "source": "UNESCO GEM – World Education Blog",
      "published": "2025-10-17T09:56:32.000Z",
      "score": 65,
      "resume_fr": "Professor Natalia I. Kucirkova, Professor of Early Childhood Development at the University of Stavanger, Norway, and The Open University, UK Around the world, major philanthropic agencies are turning to educational technology (EdTech) to improve learning. In the rush to identify tools that can quickly, cost-effectively, and reliably support children’s learning, ‘impact’ has become the central […] The post How to avoid three common pitfalls in EdTech impact evaluations appeared first on World Education Blog.",
      "tags": [],
      "breakdown": {
        "research": 0,
        "policy": 35,
        "institution": 15,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=0, Politiques=35, Institution=15, Impact=15.",
      "image": "https://world-education-blog.org/wp-content/uploads/2025/10/Untitled-Twitter-Post6.png"
    }
  ]
}