{
  "generatedAt": "2025-11-19T06:37:06.303Z",
  "model": "gpt-5",
  "profile": "balanced",
  "threshold": 65,
  "totalAnalyzed": 100,
  "totalPublished": 19,
  "publishTarget": "default",
  "debug": {
    "analysisFailed": true,
    "usedLLM": false,
    "useOpenAIEnv": false,
    "hasOpenAIKey": false,
    "minPublish": 12,
    "weightsUsed": {
      "research": 35,
      "policy": 35,
      "institution": 15,
      "impact": 15
    },
    "labelsUsed": {
      "research": "Recherche",
      "policy": "Politiques",
      "institution": "Institution",
      "impact": "Impact"
    },
    "descUsed": {
      "research": "articles/journaux, conférences, CFP, résultats scientifiques",
      "policy": "lois, régulations, standards, cadres, gouvernance",
      "institution": "communiqués des grandes agences et autorités (UNESCO, OCDE, CNIL, ministères…)",
      "impact": "impact direct pour la classe/enseignants/universités/EdTech"
    },
    "keysUsed": {
      "research": [
        "arxiv",
        "preprint",
        "doi",
        "journal",
        "conference",
        "proceedings",
        "workshop",
        "submission",
        "cfp",
        "acceptance",
        "springer",
        "wiley",
        "nature",
        "frontiers",
        "acm",
        "ieee"
      ],
      "policy": [
        "ai act",
        "regulation",
        "régulation",
        "policy",
        "politique",
        "standard",
        "framework",
        "guidance",
        "law",
        "act",
        "ordonnance",
        "décret",
        "ethics",
        "ethical"
      ],
      "institution": [
        "unesco",
        "oecd",
        "ocde",
        "cnil",
        "edps",
        "ncsc",
        "minist",
        "commission",
        "nsf",
        "ukri",
        "ies",
        "european commission"
      ],
      "impact": [
        "school",
        "education",
        "teacher",
        "enseignant",
        "k-12",
        "universit",
        "student",
        "pupil",
        "mooc",
        "classroom",
        "edtech"
      ]
    }
  },
  "items": [
    {
      "title": "Beyond Means: A Dynamic Framework for Predicting Customer Satisfaction",
      "url": "https://arxiv.org/abs/2511.14743v1",
      "source": "arXiv – cs.LG + learning analytics",
      "published": "2025-11-18T18:43:29.000Z",
      "score": 70,
      "summary_en": "Online ratings influence customer decision-making, yet standard aggregation methods, such as the sample mean, fail to adapt to quality changes over time and ignore review heterogeneity (e.g., review sentiment, a review's helpfulness). To address these challenges, we demonstrate the value of using the Gaussian process (GP) framework for rating aggregation. Specifically, we present a tailored GP model that captures the dynamics of ratings over time while additionally accounting for review heterogeneity. Based on 121,123 ratings from Yelp, we compare the predictive power of different rating aggre",
      "summary_fr": "Online ratings influence customer decision-making, yet standard aggregation methods, such as the sample mean, fail to adapt to quality changes over time and ignore review heterogeneity (e.g., review sentiment, a review's helpfulness). To address these challenges, we demonstrate the value of using the Gaussian process (GP) framework for rating aggregation. Specifically, we present a tailored GP model that captures the dynamics of ratings over time while additionally accounting for review heterogeneity. Based on 121,123 ratings from Yelp, we compare the predictive power of different rating aggre",
      "resume_fr": "Online ratings influence customer decision-making, yet standard aggregation methods, such as the sample mean, fail to adapt to quality changes over time and ignore review heterogeneity (e.g., review sentiment, a review's helpfulness). To address these challenges, we demonstrate the value of using the Gaussian process (GP) framework for rating aggregation. Specifically, we present a tailored GP model that captures the dynamics of ratings over time while additionally accounting for review heterogeneity. Based on 121,123 ratings from Yelp, we compare the predictive power of different rating aggre",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Strategic Innovation Management in the Age of Large Language Models Market Intelligence, Adaptive R&D, and Ethical Governance",
      "url": "https://arxiv.org/abs/2511.14709v1",
      "source": "arXiv – cs.CL (NLP/LLM)",
      "published": "2025-11-18T17:50:39.000Z",
      "score": 70,
      "summary_en": "This study analyzes the multiple functions of Large Language Models (LLMs) in transforming research and development (R&D) processes. By automating knowledge discovery, boosting hypothesis creation, integrating transdisciplinary insights, and enabling cooperation within innovation ecosystems, LLMs dramatically improve the efficiency and effectiveness of research processes. Through extensive analysis of scientific literature, patent databases, and experimental data, these models enable more flexible and informed R&D workflows, ultimately accelerating innovation cycles and lowering time-to-market",
      "summary_fr": "This study analyzes the multiple functions of Large Language Models (LLMs) in transforming research and development (R&D) processes. By automating knowledge discovery, boosting hypothesis creation, integrating transdisciplinary insights, and enabling cooperation within innovation ecosystems, LLMs dramatically improve the efficiency and effectiveness of research processes. Through extensive analysis of scientific literature, patent databases, and experimental data, these models enable more flexible and informed R&D workflows, ultimately accelerating innovation cycles and lowering time-to-market",
      "resume_fr": "This study analyzes the multiple functions of Large Language Models (LLMs) in transforming research and development (R&D) processes. By automating knowledge discovery, boosting hypothesis creation, integrating transdisciplinary insights, and enabling cooperation within innovation ecosystems, LLMs dramatically improve the efficiency and effectiveness of research processes. Through extensive analysis of scientific literature, patent databases, and experimental data, these models enable more flexible and informed R&D workflows, ultimately accelerating innovation cycles and lowering time-to-market",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Subword Tokenization Strategies for Kurdish Word Embeddings",
      "url": "https://arxiv.org/abs/2511.14696v1",
      "source": "arXiv – cs.CL (NLP/LLM)",
      "published": "2025-11-18T17:33:32.000Z",
      "score": 50,
      "summary_en": "We investigate tokenization strategies for Kurdish word embeddings by comparing word-level, morpheme-based, and BPE approaches on morphological similarity preservation tasks. We develop a BiLSTM-CRF morphological segmenter using bootstrapped training from minimal manual annotation and evaluate Word2Vec embeddings across comprehensive metrics including similarity preservation, clustering quality, and semantic organization. Our analysis reveals critical evaluation biases in tokenization comparison. While BPE initially appears superior in morphological similarity, it evaluates only 28.6\\% of test",
      "summary_fr": "We investigate tokenization strategies for Kurdish word embeddings by comparing word-level, morpheme-based, and BPE approaches on morphological similarity preservation tasks. We develop a BiLSTM-CRF morphological segmenter using bootstrapped training from minimal manual annotation and evaluate Word2Vec embeddings across comprehensive metrics including similarity preservation, clustering quality, and semantic organization. Our analysis reveals critical evaluation biases in tokenization comparison. While BPE initially appears superior in morphological similarity, it evaluates only 28.6\\% of test",
      "resume_fr": "We investigate tokenization strategies for Kurdish word embeddings by comparing word-level, morpheme-based, and BPE approaches on morphological similarity preservation tasks. We develop a BiLSTM-CRF morphological segmenter using bootstrapped training from minimal manual annotation and evaluate Word2Vec embeddings across comprehensive metrics including similarity preservation, clustering quality, and semantic organization. Our analysis reveals critical evaluation biases in tokenization comparison. While BPE initially appears superior in morphological similarity, it evaluates only 28.6\\% of test",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 15,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=15, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Talk, Snap, Complain: Validation-Aware Multimodal Expert Framework for Fine-Grained Customer Grievances",
      "url": "https://arxiv.org/abs/2511.14693v1",
      "source": "arXiv – cs.CL (NLP/LLM)",
      "published": "2025-11-18T17:29:28.000Z",
      "score": 70,
      "summary_en": "Existing approaches to complaint analysis largely rely on unimodal, short-form content such as tweets or product reviews. This work advances the field by leveraging multimodal, multi-turn customer support dialogues, where users often share both textual complaints and visual evidence (e.g., screenshots, product photos) to enable fine-grained classification of complaint aspects and severity. We introduce VALOR, a Validation-Aware Learner with Expert Routing, tailored for this multimodal setting. It employs a multi-expert reasoning setup using large-scale generative models with Chain-of-Thought (",
      "summary_fr": "Existing approaches to complaint analysis largely rely on unimodal, short-form content such as tweets or product reviews. This work advances the field by leveraging multimodal, multi-turn customer support dialogues, where users often share both textual complaints and visual evidence (e.g., screenshots, product photos) to enable fine-grained classification of complaint aspects and severity. We introduce VALOR, a Validation-Aware Learner with Expert Routing, tailored for this multimodal setting. It employs a multi-expert reasoning setup using large-scale generative models with Chain-of-Thought (",
      "resume_fr": "Existing approaches to complaint analysis largely rely on unimodal, short-form content such as tweets or product reviews. This work advances the field by leveraging multimodal, multi-turn customer support dialogues, where users often share both textual complaints and visual evidence (e.g., screenshots, product photos) to enable fine-grained classification of complaint aspects and severity. We introduce VALOR, a Validation-Aware Learner with Expert Routing, tailored for this multimodal setting. It employs a multi-expert reasoning setup using large-scale generative models with Chain-of-Thought (",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Quadratic Term Correction on Heaps' Law",
      "url": "https://arxiv.org/abs/2511.14683v1",
      "source": "arXiv – cs.CL (NLP/LLM)",
      "published": "2025-11-18T17:22:00.000Z",
      "score": 70,
      "summary_en": "Heaps' or Herdan's law characterizes the word-type vs. word-token relation by a power-law function, which is concave in linear-linear scale but a straight line in log-log scale. However, it has been observed that even in log-log scale, the type-token curve is still slightly concave, invalidating the power-law relation. At the next-order approximation, we have shown, by twenty English novels or writings (some are translated from another language to English), that quadratic functions in log-log scale fit the type-token data perfectly. Regression analyses of log(type)-log(token) data with both a ",
      "summary_fr": "Heaps' or Herdan's law characterizes the word-type vs. word-token relation by a power-law function, which is concave in linear-linear scale but a straight line in log-log scale. However, it has been observed that even in log-log scale, the type-token curve is still slightly concave, invalidating the power-law relation. At the next-order approximation, we have shown, by twenty English novels or writings (some are translated from another language to English), that quadratic functions in log-log scale fit the type-token data perfectly. Regression analyses of log(type)-log(token) data with both a ",
      "resume_fr": "Heaps' or Herdan's law characterizes the word-type vs. word-token relation by a power-law function, which is concave in linear-linear scale but a straight line in log-log scale. However, it has been observed that even in log-log scale, the type-token curve is still slightly concave, invalidating the power-law relation. At the next-order approximation, we have shown, by twenty English novels or writings (some are translated from another language to English), that quadratic functions in log-log scale fit the type-token data perfectly. Regression analyses of log(type)-log(token) data with both a ",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Making Evidence Actionable in Adaptive Learning",
      "url": "https://arxiv.org/abs/2511.14052v1",
      "source": "arXiv – cs.AI + education/MOOC",
      "published": "2025-11-18T02:06:08.000Z",
      "score": 85,
      "summary_en": "Adaptive learning often diagnoses precisely yet intervenes weakly, yielding help that is mistimed or misaligned. This study presents evidence supporting an instructor-governed feedback loop that converts concept-level assessment evidence into vetted micro-interventions. The adaptive learning algorithm contains three safeguards: adequacy as a hard guarantee of gap closure, attention as a budgeted constraint for time and redundancy, and diversity as protection against overfitting to a single resource. We formalize intervention assignment as a binary integer program with constraints for coverage,",
      "summary_fr": "Adaptive learning often diagnoses precisely yet intervenes weakly, yielding help that is mistimed or misaligned. This study presents evidence supporting an instructor-governed feedback loop that converts concept-level assessment evidence into vetted micro-interventions. The adaptive learning algorithm contains three safeguards: adequacy as a hard guarantee of gap closure, attention as a budgeted constraint for time and redundancy, and diversity as protection against overfitting to a single resource. We formalize intervention assignment as a binary integer program with constraints for coverage,",
      "resume_fr": "Adaptive learning often diagnoses precisely yet intervenes weakly, yielding help that is mistimed or misaligned. This study presents evidence supporting an instructor-governed feedback loop that converts concept-level assessment evidence into vetted micro-interventions. The adaptive learning algorithm contains three safeguards: adequacy as a hard guarantee of gap closure, attention as a budgeted constraint for time and redundancy, and diversity as protection against overfitting to a single resource. We formalize intervention assignment as a binary integer program with constraints for coverage,",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Exploring the Use of ChatGPT by Computer Science Students in Software Development: Applications, Ethical Considerations, and Insights for Engineering Education",
      "url": "https://arxiv.org/abs/2511.13996v1",
      "source": "arXiv – cs.HC + education",
      "published": "2025-11-17T23:54:08.000Z",
      "score": 85,
      "summary_en": "ChatGPT has been increasingly used in computer science, offering efficient support across software development tasks. While it helps students navigate programming challenges, its use also raises concerns about academic integrity and overreliance. Despite growing interest in this topic, prior research has largely relied on surveys, emphasizing trends over in-depth analysis of students' strategies and ethical awareness. This study complements existing work through a qualitative investigation of how computer science students in one UK institution strategically and ethically engage with ChatGPT in",
      "summary_fr": "ChatGPT has been increasingly used in computer science, offering efficient support across software development tasks. While it helps students navigate programming challenges, its use also raises concerns about academic integrity and overreliance. Despite growing interest in this topic, prior research has largely relied on surveys, emphasizing trends over in-depth analysis of students' strategies and ethical awareness. This study complements existing work through a qualitative investigation of how computer science students in one UK institution strategically and ethically engage with ChatGPT in",
      "resume_fr": "ChatGPT has been increasingly used in computer science, offering efficient support across software development tasks. While it helps students navigate programming challenges, its use also raises concerns about academic integrity and overreliance. Despite growing interest in this topic, prior research has largely relied on surveys, emphasizing trends over in-depth analysis of students' strategies and ethical awareness. This study complements existing work through a qualitative investigation of how computer science students in one UK institution strategically and ethically engage with ChatGPT in",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "ST-ProC: A Graph-Prototypical Framework for Robust Semi-Supervised Travel Mode Identification",
      "url": "https://arxiv.org/abs/2511.13702v1",
      "source": "arXiv – cs.LG + learning analytics",
      "published": "2025-11-17T18:52:11.000Z",
      "score": 70,
      "resume_fr": "Travel mode identification (TMI) from GPS trajectories is critical for urban intelligence, but is hampered by the high cost of annotation, leading to severe label scarcity. Prevailing semi-supervised learning (SSL) methods are ill-suited for this task, as they suffer from catastrophic confirmation bias and ignore the intrinsic data manifold. We propose ST-ProC, a novel graph-prototypical multi-objective SSL framework to address these limitations. Our framework synergizes a graph-prototypical core with foundational SSL Support. The core exploits the data manifold via graph regularization, proto",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Making Evidence Actionable in Adaptive Learning Closing the Diagnostic Pedagogical Loop",
      "url": "https://arxiv.org/abs/2511.13542v1",
      "source": "arXiv – cs.AI + education/MOOC",
      "published": "2025-11-17T16:15:50.000Z",
      "score": 85,
      "summary_en": "Adaptive learning often diagnoses precisely yet intervenes weakly, producing help that is mistimed or misaligned. This study presents evidence supporting an instructor-governed feedback loop that converts concept-level assessment evidence into vetted microinterventions. The adaptive learning algorithm includes three safeguards: adequacy as a hard guarantee of gap closure, attention as a budgeted limit for time and redundancy, and diversity as protection against overfitting to a single resource. We formulate intervention assignment as a binary integer program with constraints for coverage, time",
      "summary_fr": "Adaptive learning often diagnoses precisely yet intervenes weakly, producing help that is mistimed or misaligned. This study presents evidence supporting an instructor-governed feedback loop that converts concept-level assessment evidence into vetted microinterventions. The adaptive learning algorithm includes three safeguards: adequacy as a hard guarantee of gap closure, attention as a budgeted limit for time and redundancy, and diversity as protection against overfitting to a single resource. We formulate intervention assignment as a binary integer program with constraints for coverage, time",
      "resume_fr": "Adaptive learning often diagnoses precisely yet intervenes weakly, producing help that is mistimed or misaligned. This study presents evidence supporting an instructor-governed feedback loop that converts concept-level assessment evidence into vetted microinterventions. The adaptive learning algorithm includes three safeguards: adequacy as a hard guarantee of gap closure, attention as a budgeted limit for time and redundancy, and diversity as protection against overfitting to a single resource. We formulate intervention assignment as a binary integer program with constraints for coverage, time",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "The Quick Red Fox gets the best Data Driven Classroom Interviews: A manual for an interview app and its associated methodology",
      "url": "https://arxiv.org/abs/2511.13466v1",
      "source": "arXiv – cs.HC + education",
      "published": "2025-11-17T15:08:47.000Z",
      "score": 50,
      "resume_fr": "Data Driven Classroom Interviews (DDCIs) are an interviewing technique that is facilitated by recent technological developments in the learning analytics community. DDCIs are short, targeted interviews that allow researchers to contextualize students' interactions with a digital learning environment (e.g., intelligent tutoring systems or educational games) while minimizing the amount of time that the researcher interrupts that learning experience, and focusing researcher time on the events they most want to focus on DDCIs are facilitated by a research tool called the Quick Red Fox (QRF)--an op",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Examining the Usage of Generative AI Models in Student Learning Activities for Software Programming",
      "url": "https://arxiv.org/abs/2511.13271v1",
      "source": "arXiv – cs.AI + education/MOOC",
      "published": "2025-11-17T11:42:24.000Z",
      "score": 100,
      "summary_en": "The rise of Generative AI (GenAI) tools like ChatGPT has created new opportunities and challenges for computing education. Existing research has primarily focused on GenAI's ability to complete educational tasks and its impact on student performance, often overlooking its effects on knowledge gains. In this study, we investigate how GenAI assistance compares to conventional online resources in supporting knowledge gains across different proficiency levels. We conducted a controlled user experiment with 24 undergraduate students of two different levels of programming experience (beginner, inter",
      "summary_fr": "The rise of Generative AI (GenAI) tools like ChatGPT has created new opportunities and challenges for computing education. Existing research has primarily focused on GenAI's ability to complete educational tasks and its impact on student performance, often overlooking its effects on knowledge gains. In this study, we investigate how GenAI assistance compares to conventional online resources in supporting knowledge gains across different proficiency levels. We conducted a controlled user experiment with 24 undergraduate students of two different levels of programming experience (beginner, inter",
      "resume_fr": "The rise of Generative AI (GenAI) tools like ChatGPT has created new opportunities and challenges for computing education. Existing research has primarily focused on GenAI's ability to complete educational tasks and its impact on student performance, often overlooking its effects on knowledge gains. In this study, we investigate how GenAI assistance compares to conventional online resources in supporting knowledge gains across different proficiency levels. We conducted a controlled user experiment with 24 undergraduate students of two different levels of programming experience (beginner, inter",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 15,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=15, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "SynthGuard: An Open Platform for Detecting AI-Generated Multimedia with Multimodal LLMs",
      "url": "https://arxiv.org/abs/2511.12404v1",
      "source": "arXiv – cs.AI + education/MOOC",
      "published": "2025-11-16T00:50:24.000Z",
      "score": 50,
      "resume_fr": "Artificial Intelligence (AI) has made it possible for anyone to create images, audio, and video with unprecedented ease, enriching education, communication, and creative expression. At the same time, the rapid rise of AI-generated media has introduced serious risks, including misinformation, identity misuse, and the erosion of public trust as synthetic content becomes increasingly indistinguishable from real media. Although deepfake detection has advanced, many existing tools remain closed-source, limited in modality, or lacking transparency and educational value, making it difficult for users",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Students Compete—and Cooperate—in FIRST Global Robotics Challenge",
      "url": "https://spectrum.ieee.org/first-global-robotics-challenge",
      "source": "IEEE Spectrum – AI",
      "published": "2025-11-15T14:00:02.000Z",
      "score": 50,
      "resume_fr": "Aspiring engineers from 191 countries gathered in Panama City in October to compete in the FIRST Global Robotics Challenge. The annual contest aims to foster problem-solving, cooperation, and inspire the next generation of engineers through three challenges that are inspired by a different theme every year. Teams of students from 14 to 18 years old from around the world compete in the three day event, remotely operating their robots to complete the challenges. This year’s topic was “Eco-equilibrium,” emphasizing the importance of preserving ecosystems and protecting vulnerable species. Turning",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=0, Impact=15.",
      "image": "https://spectrum.ieee.org/media-library/image.jpg?id=62186165&width=1200&height=600&coordinates=0%2C232%2C0%2C232"
    },
    {
      "title": "CollaClassroom: An AI-Augmented Collaborative Learning Platform with LLM Support in the Context of Bangladeshi University Students",
      "url": "https://arxiv.org/abs/2511.11823v1",
      "source": "arXiv – cs.HC + education",
      "published": "2025-11-14T19:23:42.000Z",
      "score": 50,
      "resume_fr": "CollaClassroom is an AI-enhanced platform that embeds large language models (LLMs) into both individual and group study panels to support real-time collaboration. We evaluate CollaClassroom with Bangladeshi university students (N = 12) through a small-group study session and a pre-post survey. Participants have substantial prior experience with collaborative learning and LLMs and express strong receptivity to LLM-assisted study (92% agree/strongly agree). Usability ratings are positive, including high learnability(67% \"easy\"), strong reliability (83% \"reliable\"), and low frustration (83% \"not ",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Differences in the Moral Foundations of Large Language Models",
      "url": "https://arxiv.org/abs/2511.11790v1",
      "source": "arXiv – cs.AI + education/MOOC",
      "published": "2025-11-14T18:21:22.000Z",
      "score": 50,
      "resume_fr": "Large language models are increasingly being used in critical domains of politics, business, and education, but the nature of their normative ethical judgment remains opaque. Alignment research has, to date, not sufficiently utilized perspectives and insights from the field of moral psychology to inform training and evaluation of frontier models. I perform a synthetic experiment on a wide range of models from most major model providers using Jonathan Haidt's influential moral foundations theory (MFT) to elicit diverse value judgments from LLMs. Using multiple descriptive statistical approaches",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Exploring The Interaction-Outcome Paradox: Seemingly Richer and More Self-Aware Interactions with LLMs May Not Yet Lead to Better Learning",
      "url": "https://arxiv.org/abs/2511.09458v1",
      "source": "arXiv – cs.HC + education",
      "published": "2025-11-12T16:18:36.000Z",
      "score": 85,
      "resume_fr": "While Large Language Models (LLMs) have transformed the user interface for learning, moving from keyword search to natural language dialogue, their impact on educational outcomes remains unclear. We present a controlled study (N=20) that directly compares the learning interaction and outcomes between LLM and search-based interfaces. We found that although LLMs elicit richer and nuanced interactions from a learner, they do not produce broadly better learning outcomes. In this paper, we explore this the ``Interaction-Outcome Paradox.'' To explain this, we discuss the concept of a cognitive shift",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Densing law of LLMs",
      "url": "https://www.nature.com/articles/s42256-025-01137-0",
      "source": "Nature Machine Intelligence",
      "published": "2025-11-06T00:00:00.000Z",
      "score": 70,
      "summary_en": "",
      "summary_fr": "",
      "resume_fr": "",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=0.",
      "image": "https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fs42256-025-01137-0/MediaObjects/42256_2025_1137_Fig1_HTML.png"
    },
    {
      "title": "Interpersonal neural synchronization underlies interactive concept learning in older adults",
      "url": "https://www.nature.com/articles/s41539-025-00368-5",
      "source": "npj Science of Learning (Nature)",
      "published": "2025-10-31T00:00:00.000Z",
      "score": 85,
      "summary_en": "",
      "summary_fr": "",
      "resume_fr": "",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 15,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=15, Impact=0.",
      "image": "https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fs41539-025-00368-5/MediaObjects/41539_2025_368_Fig1_HTML.png"
    },
    {
      "title": "How to avoid three common pitfalls in EdTech impact evaluations",
      "url": "https://world-education-blog.org/2025/10/17/how-to-avoid-three-common-pitfalls-in-edtech-impact-evaluations/",
      "source": "UNESCO GEM – World Education Blog",
      "published": "2025-10-17T09:56:32.000Z",
      "score": 65,
      "summary_en": "Professor Natalia I. Kucirkova, Professor of Early Childhood Development at the University of Stavanger, Norway, and The Open University, UK Around the world, major philanthropic agencies are turning to educational technology (EdTech) to improve learning. In the rush to identify tools that can quickly, cost-effectively, and reliably support children’s learning, ‘impact’ has become the central […] The post How to avoid three common pitfalls in EdTech impact evaluations appeared first on World Education Blog.",
      "summary_fr": "Professor Natalia I. Kucirkova, Professor of Early Childhood Development at the University of Stavanger, Norway, and The Open University, UK Around the world, major philanthropic agencies are turning to educational technology (EdTech) to improve learning. In the rush to identify tools that can quickly, cost-effectively, and reliably support children’s learning, ‘impact’ has become the central […] The post How to avoid three common pitfalls in EdTech impact evaluations appeared first on World Education Blog.",
      "resume_fr": "Professor Natalia I. Kucirkova, Professor of Early Childhood Development at the University of Stavanger, Norway, and The Open University, UK Around the world, major philanthropic agencies are turning to educational technology (EdTech) to improve learning. In the rush to identify tools that can quickly, cost-effectively, and reliably support children’s learning, ‘impact’ has become the central […] The post How to avoid three common pitfalls in EdTech impact evaluations appeared first on World Education Blog.",
      "tags": [],
      "breakdown": {
        "research": 0,
        "policy": 35,
        "institution": 15,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=0, Politiques=35, Institution=15, Impact=15.",
      "image": "https://world-education-blog.org/wp-content/uploads/2025/10/Untitled-Twitter-Post6.png"
    }
  ]
}