{
  "generatedAt": "2025-12-17T06:41:27.066Z",
  "model": "gpt-5",
  "profile": "balanced",
  "threshold": 65,
  "totalAnalyzed": 100,
  "totalPublished": 60,
  "publishTarget": "default",
  "debug": {
    "analysisFailed": true,
    "usedLLM": false,
    "useOpenAIEnv": true,
    "hasOpenAIKey": true,
    "minPublish": 12,
    "weightsUsed": {
      "research": 35,
      "policy": 35,
      "institution": 15,
      "impact": 15
    },
    "labelsUsed": {
      "research": "Recherche",
      "policy": "Politiques",
      "institution": "Institution",
      "impact": "Impact"
    },
    "descUsed": {
      "research": "articles/journaux, conférences, CFP, résultats scientifiques",
      "policy": "lois, régulations, standards, cadres, gouvernance",
      "institution": "communiqués des grandes agences et autorités (UNESCO, OCDE, CNIL, ministères…)",
      "impact": "impact direct pour la classe/enseignants/universités/EdTech"
    },
    "keysUsed": {
      "research": [
        "arxiv",
        "preprint",
        "doi",
        "journal",
        "conference",
        "proceedings",
        "workshop",
        "submission",
        "cfp",
        "acceptance",
        "springer",
        "wiley",
        "nature",
        "frontiers",
        "acm",
        "ieee"
      ],
      "policy": [
        "ai act",
        "regulation",
        "régulation",
        "policy",
        "politique",
        "standard",
        "framework",
        "guidance",
        "law",
        "act",
        "ordonnance",
        "décret",
        "ethics",
        "ethical"
      ],
      "institution": [
        "unesco",
        "oecd",
        "ocde",
        "cnil",
        "edps",
        "ncsc",
        "minist",
        "commission",
        "nsf",
        "ukri",
        "ies",
        "european commission"
      ],
      "impact": [
        "school",
        "education",
        "teacher",
        "enseignant",
        "k-12",
        "universit",
        "student",
        "pupil",
        "mooc",
        "classroom",
        "edtech"
      ]
    }
  },
  "items": [
    {
      "title": "Beyond Lipschitz Continuity and Monotonicity: Fractal and Chaotic Activation Functions in Echo State Networks",
      "url": "https://arxiv.org/abs/2512.14675v1",
      "source": "arXiv – cs.LG + learning analytics",
      "published": "2025-12-16T18:41:01.000Z",
      "score": 70,
      "summary_en": "Contemporary reservoir computing relies heavily on smooth, globally Lipschitz continuous activation functions, limiting applications in defense, disaster response, and pharmaceutical modeling where robust operation under extreme conditions is critical. We systematically investigate non-smooth activation functions, including chaotic, stochastic, and fractal variants, in echo state networks. Through comprehensive parameter sweeps across 36,610 reservoir configurations, we demonstrate that several non-smooth functions not only maintain the Echo State Property (ESP) but outperform traditional smoo",
      "summary_fr": "Contemporary reservoir computing relies heavily on smooth, globally Lipschitz continuous activation functions, limiting applications in defense, disaster response, and pharmaceutical modeling where robust operation under extreme conditions is critical. We systematically investigate non-smooth activation functions, including chaotic, stochastic, and fractal variants, in echo state networks. Through comprehensive parameter sweeps across 36,610 reservoir configurations, we demonstrate that several non-smooth functions not only maintain the Echo State Property (ESP) but outperform traditional smoo",
      "resume_fr": "Contemporary reservoir computing relies heavily on smooth, globally Lipschitz continuous activation functions, limiting applications in defense, disaster response, and pharmaceutical modeling where robust operation under extreme conditions is critical. We systematically investigate non-smooth activation functions, including chaotic, stochastic, and fractal variants, in echo state networks. Through comprehensive parameter sweeps across 36,610 reservoir configurations, we demonstrate that several non-smooth functions not only maintain the Echo State Property (ESP) but outperform traditional smoo",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "DiffusionBrowser: Interactive Diffusion Previews via Multi-Branch Decoders",
      "url": "https://arxiv.org/abs/2512.13690v1",
      "source": "arXiv – cs.LG + learning analytics",
      "published": "2025-12-15T18:59:57.000Z",
      "score": 70,
      "summary_en": "Video diffusion models have revolutionized generative video synthesis, but they are imprecise, slow, and can be opaque during generation -- keeping users in the dark for a prolonged period. In this work, we propose DiffusionBrowser, a model-agnostic, lightweight decoder framework that allows users to interactively generate previews at any point (timestep or transformer block) during the denoising process. Our model can generate multi-modal preview representations that include RGB and scene intrinsics at more than 4$\\times$ real-time speed (less than 1 second for a 4-second video) that convey c",
      "summary_fr": "Video diffusion models have revolutionized generative video synthesis, but they are imprecise, slow, and can be opaque during generation -- keeping users in the dark for a prolonged period. In this work, we propose DiffusionBrowser, a model-agnostic, lightweight decoder framework that allows users to interactively generate previews at any point (timestep or transformer block) during the denoising process. Our model can generate multi-modal preview representations that include RGB and scene intrinsics at more than 4$\\times$ real-time speed (less than 1 second for a 4-second video) that convey c",
      "resume_fr": "Video diffusion models have revolutionized generative video synthesis, but they are imprecise, slow, and can be opaque during generation -- keeping users in the dark for a prolonged period. In this work, we propose DiffusionBrowser, a model-agnostic, lightweight decoder framework that allows users to interactively generate previews at any point (timestep or transformer block) during the denoising process. Our model can generate multi-modal preview representations that include RGB and scene intrinsics at more than 4$\\times$ real-time speed (less than 1 second for a 4-second video) that convey c",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Towards Interactive Intelligence for Digital Humans",
      "url": "https://arxiv.org/abs/2512.13674v1",
      "source": "arXiv – cs.CL (NLP/LLM)",
      "published": "2025-12-15T18:57:35.000Z",
      "score": 70,
      "summary_en": "We introduce Interactive Intelligence, a novel paradigm of digital human that is capable of personality-aligned expression, adaptive interaction, and self-evolution. To realize this, we present Mio (Multimodal Interactive Omni-Avatar), an end-to-end framework composed of five specialized modules: Thinker, Talker, Face Animator, Body Animator, and Renderer. This unified architecture integrates cognitive reasoning with real-time multimodal embodiment to enable fluid, consistent interaction. Furthermore, we establish a new benchmark to rigorously evaluate the capabilities of interactive intellige",
      "summary_fr": "We introduce Interactive Intelligence, a novel paradigm of digital human that is capable of personality-aligned expression, adaptive interaction, and self-evolution. To realize this, we present Mio (Multimodal Interactive Omni-Avatar), an end-to-end framework composed of five specialized modules: Thinker, Talker, Face Animator, Body Animator, and Renderer. This unified architecture integrates cognitive reasoning with real-time multimodal embodiment to enable fluid, consistent interaction. Furthermore, we establish a new benchmark to rigorously evaluate the capabilities of interactive intellige",
      "resume_fr": "We introduce Interactive Intelligence, a novel paradigm of digital human that is capable of personality-aligned expression, adaptive interaction, and self-evolution. To realize this, we present Mio (Multimodal Interactive Omni-Avatar), an end-to-end framework composed of five specialized modules: Thinker, Talker, Face Animator, Body Animator, and Renderer. This unified architecture integrates cognitive reasoning with real-time multimodal embodiment to enable fluid, consistent interaction. Furthermore, we establish a new benchmark to rigorously evaluate the capabilities of interactive intellige",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "SEDULity: A Proof-of-Learning Framework for Distributed and Secure Blockchains with Efficient Useful Work",
      "url": "https://arxiv.org/abs/2512.13666v1",
      "source": "arXiv – cs.LG + learning analytics",
      "published": "2025-12-15T18:55:20.000Z",
      "score": 70,
      "summary_en": "The security and decentralization of Proof-of-Work (PoW) have been well-tested in existing blockchain systems. However, its tremendous energy waste has raised concerns about sustainability. Proof-of-Useful-Work (PoUW) aims to redirect the meaningless computation to meaningful tasks such as solving machine learning (ML) problems, giving rise to the branch of Proof-of-Learning (PoL). While previous studies have proposed various PoLs, they all, to some degree, suffer from security, decentralization, or efficiency issues. In this paper, we propose a PoL framework that trains ML models efficiently ",
      "summary_fr": "The security and decentralization of Proof-of-Work (PoW) have been well-tested in existing blockchain systems. However, its tremendous energy waste has raised concerns about sustainability. Proof-of-Useful-Work (PoUW) aims to redirect the meaningless computation to meaningful tasks such as solving machine learning (ML) problems, giving rise to the branch of Proof-of-Learning (PoL). While previous studies have proposed various PoLs, they all, to some degree, suffer from security, decentralization, or efficiency issues. In this paper, we propose a PoL framework that trains ML models efficiently ",
      "resume_fr": "The security and decentralization of Proof-of-Work (PoW) have been well-tested in existing blockchain systems. However, its tremendous energy waste has raised concerns about sustainability. Proof-of-Useful-Work (PoUW) aims to redirect the meaningless computation to meaningful tasks such as solving machine learning (ML) problems, giving rise to the branch of Proof-of-Learning (PoL). While previous studies have proposed various PoLs, they all, to some degree, suffer from security, decentralization, or efficiency issues. In this paper, we propose a PoL framework that trains ML models efficiently ",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Embedding-Based Rankings of Educational Resources based on Learning Outcome Alignment: Benchmarking, Expert Validation, and Learner Performance",
      "url": "https://arxiv.org/abs/2512.13658v1",
      "source": "arXiv – cs.AI + education/MOOC",
      "published": "2025-12-15T18:51:00.000Z",
      "score": 50,
      "summary_en": "As the online learning landscape evolves, the need for personalization is increasingly evident. Although educational resources are burgeoning, educators face challenges selecting materials that both align with intended learning outcomes and address diverse learner needs. Large Language Models (LLMs) are attracting growing interest for their potential to create learning resources that better support personalization, but verifying coverage of intended outcomes still requires human alignment review, which is costly and limits scalability. We propose a framework that supports the cost-effective au",
      "summary_fr": "As the online learning landscape evolves, the need for personalization is increasingly evident. Although educational resources are burgeoning, educators face challenges selecting materials that both align with intended learning outcomes and address diverse learner needs. Large Language Models (LLMs) are attracting growing interest for their potential to create learning resources that better support personalization, but verifying coverage of intended outcomes still requires human alignment review, which is costly and limits scalability. We propose a framework that supports the cost-effective au",
      "resume_fr": "As the online learning landscape evolves, the need for personalization is increasingly evident. Although educational resources are burgeoning, educators face challenges selecting materials that both align with intended learning outcomes and address diverse learner needs. Large Language Models (LLMs) are attracting growing interest for their potential to create learning resources that better support personalization, but verifying coverage of intended outcomes still requires human alignment review, which is costly and limits scalability. We propose a framework that supports the cost-effective au",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Temporal Tokenization Strategies for Event Sequence Modeling with Large Language Models",
      "url": "https://arxiv.org/abs/2512.13618v1",
      "source": "arXiv – cs.CL (NLP/LLM)",
      "published": "2025-12-15T18:10:51.000Z",
      "score": 50,
      "summary_en": "Representing continuous time is a critical and under-explored challenge in modeling temporal event sequences with large language models (LLMs). Various strategies like byte-level representations or calendar tokens have been proposed. However, the optimal approach remains unclear, especially given the diverse statistical distributions of real-world event data, which range from smooth log-normal to discrete, spiky patterns. This paper presents the first empirical study of temporal tokenization for event sequences, comparing distinct encoding strategies: naive numeric strings, high-precision byte",
      "summary_fr": "Representing continuous time is a critical and under-explored challenge in modeling temporal event sequences with large language models (LLMs). Various strategies like byte-level representations or calendar tokens have been proposed. However, the optimal approach remains unclear, especially given the diverse statistical distributions of real-world event data, which range from smooth log-normal to discrete, spiky patterns. This paper presents the first empirical study of temporal tokenization for event sequences, comparing distinct encoding strategies: naive numeric strings, high-precision byte",
      "resume_fr": "Representing continuous time is a critical and under-explored challenge in modeling temporal event sequences with large language models (LLMs). Various strategies like byte-level representations or calendar tokens have been proposed. However, the optimal approach remains unclear, especially given the diverse statistical distributions of real-world event data, which range from smooth log-normal to discrete, spiky patterns. This paper presents the first empirical study of temporal tokenization for event sequences, comparing distinct encoding strategies: naive numeric strings, high-precision byte",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 15,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=15, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Beyond Procedural Compliance: Human Oversight as a Dimension of Well-being Efficacy in AI Governance",
      "url": "https://arxiv.org/abs/2512.13768v1",
      "source": "arXiv – cs.HC + education",
      "published": "2025-12-15T16:20:59.000Z",
      "score": 50,
      "summary_en": "Major AI ethics guidelines and laws, including the EU AI Act, call for effective human oversight, but do not define it as a distinct and developable capacity. This paper introduces human oversight as a well-being capacity, situated within the emerging Well-being Efficacy framework. The concept integrates AI literacy, ethical discernment, and awareness of human needs, acknowledging that some needs may be conflicting or harmful. Because people inevitably project desires, fears, and interests into AI systems, oversight requires the competence to examine and, when necessary, restrain problematic d",
      "summary_fr": "Major AI ethics guidelines and laws, including the EU AI Act, call for effective human oversight, but do not define it as a distinct and developable capacity. This paper introduces human oversight as a well-being capacity, situated within the emerging Well-being Efficacy framework. The concept integrates AI literacy, ethical discernment, and awareness of human needs, acknowledging that some needs may be conflicting or harmful. Because people inevitably project desires, fears, and interests into AI systems, oversight requires the competence to examine and, when necessary, restrain problematic d",
      "resume_fr": "Major AI ethics guidelines and laws, including the EU AI Act, call for effective human oversight, but do not define it as a distinct and developable capacity. This paper introduces human oversight as a well-being capacity, situated within the emerging Well-being Efficacy framework. The concept integrates AI literacy, ethical discernment, and awareness of human needs, acknowledging that some needs may be conflicting or harmful. Because people inevitably project desires, fears, and interests into AI systems, oversight requires the competence to examine and, when necessary, restrain problematic d",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Socratic Students: Teaching Language Models to Learn by Asking Questions",
      "url": "https://arxiv.org/abs/2512.13102v1",
      "source": "arXiv – cs.AI + education/MOOC",
      "published": "2025-12-15T08:59:19.000Z",
      "score": 50,
      "summary_en": "Large Language Models (LLMs) excel at static interactions, where they answer user queries by retrieving knowledge encoded in their parameters. However, in many real-world settings, such as educational tutoring or medical assistance, relevant information is not directly available and must be actively acquired through dynamic interactions. An interactive agent would recognize its own uncertainty, ask targeted questions, and retain new knowledge efficiently. Prior work has primarily explored effective ways for a teacher to instruct the student, where the teacher identifies student gaps and provid",
      "summary_fr": "Large Language Models (LLMs) excel at static interactions, where they answer user queries by retrieving knowledge encoded in their parameters. However, in many real-world settings, such as educational tutoring or medical assistance, relevant information is not directly available and must be actively acquired through dynamic interactions. An interactive agent would recognize its own uncertainty, ask targeted questions, and retain new knowledge efficiently. Prior work has primarily explored effective ways for a teacher to instruct the student, where the teacher identifies student gaps and provid",
      "resume_fr": "Large Language Models (LLMs) excel at static interactions, where they answer user queries by retrieving knowledge encoded in their parameters. However, in many real-world settings, such as educational tutoring or medical assistance, relevant information is not directly available and must be actively acquired through dynamic interactions. An interactive agent would recognize its own uncertainty, ask targeted questions, and retain new knowledge efficiently. Prior work has primarily explored effective ways for a teacher to instruct the student, where the teacher identifies student gaps and provid",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Information-Consistent Language Model Recommendations through Group Relative Policy Optimization",
      "url": "https://arxiv.org/abs/2512.12858v1",
      "source": "arXiv – cs.AI + education/MOOC",
      "published": "2025-12-14T21:52:31.000Z",
      "score": 85,
      "summary_en": "Large Language Models (LLMs) are increasingly deployed in business-critical domains such as finance, education, healthcare, and customer support, where users expect consistent and reliable recommendations. Yet LLMs often exhibit variability when prompts are phrased with minor differences, even when semantically equivalent. Such inconsistency undermines trust, complicates compliance, and disrupts user experience. While personalization is desirable in certain contexts, many enterprise scenarios-such as HR onboarding, customer support, or policy disclosure-require invariant information delivery r",
      "summary_fr": "Large Language Models (LLMs) are increasingly deployed in business-critical domains such as finance, education, healthcare, and customer support, where users expect consistent and reliable recommendations. Yet LLMs often exhibit variability when prompts are phrased with minor differences, even when semantically equivalent. Such inconsistency undermines trust, complicates compliance, and disrupts user experience. While personalization is desirable in certain contexts, many enterprise scenarios-such as HR onboarding, customer support, or policy disclosure-require invariant information delivery r",
      "resume_fr": "Large Language Models (LLMs) are increasingly deployed in business-critical domains such as finance, education, healthcare, and customer support, where users expect consistent and reliable recommendations. Yet LLMs often exhibit variability when prompts are phrased with minor differences, even when semantically equivalent. Such inconsistency undermines trust, complicates compliance, and disrupts user experience. While personalization is desirable in certain contexts, many enterprise scenarios-such as HR onboarding, customer support, or policy disclosure-require invariant information delivery r",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Exploring the Modular Integration of \"AI + Architecture\" Pedagogy in Undergraduate Design Education: A Case Study of Architectural Design III/IV Courses at Zhejiang University",
      "url": "https://arxiv.org/abs/2512.13730v1",
      "source": "arXiv – cs.AI + education/MOOC",
      "published": "2025-12-14T02:38:21.000Z",
      "score": 50,
      "summary_en": "This study investigates AI integration in architectural education through a teaching experiment in Zhejiang University's 2024-25 grade three undergraduate design studio. Adopting a dual-module framework (20-hour AI training + embedded ethics discussions), the course introduced deep learning models, LLMs, AIGC, LoRA, and ComfyUI while maintaining the original curriculum structure, supported by dedicated technical instructors. Findings demonstrate the effectiveness of phased guidance, balanced technical-ethical approaches, and institutional support. The model improved students' digital skills an",
      "summary_fr": "This study investigates AI integration in architectural education through a teaching experiment in Zhejiang University's 2024-25 grade three undergraduate design studio. Adopting a dual-module framework (20-hour AI training + embedded ethics discussions), the course introduced deep learning models, LLMs, AIGC, LoRA, and ComfyUI while maintaining the original curriculum structure, supported by dedicated technical instructors. Findings demonstrate the effectiveness of phased guidance, balanced technical-ethical approaches, and institutional support. The model improved students' digital skills an",
      "resume_fr": "This study investigates AI integration in architectural education through a teaching experiment in Zhejiang University's 2024-25 grade three undergraduate design studio. Adopting a dual-module framework (20-hour AI training + embedded ethics discussions), the course introduced deep learning models, LLMs, AIGC, LoRA, and ComfyUI while maintaining the original curriculum structure, supported by dedicated technical instructors. Findings demonstrate the effectiveness of phased guidance, balanced technical-ethical approaches, and institutional support. The model improved students' digital skills an",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "SafeGen: Embedding Ethical Safeguards in Text-to-Image Generation",
      "url": "https://arxiv.org/abs/2512.12501v1",
      "source": "arXiv – cs.AI + education/MOOC",
      "published": "2025-12-14T00:18:10.000Z",
      "score": 85,
      "summary_en": "Generative Artificial Intelligence (AI) has created unprecedented opportunities for creative expression, education, and research. Text-to-image systems such as DALL.E, Stable Diffusion, and Midjourney can now convert ideas into visuals within seconds, but they also present a dual-use dilemma, raising critical ethical concerns: amplifying societal biases, producing high-fidelity disinformation, and violating intellectual property. This paper introduces SafeGen, a framework that embeds ethical safeguards directly into the text-to-image generation pipeline, grounding its design in established pri",
      "summary_fr": "Generative Artificial Intelligence (AI) has created unprecedented opportunities for creative expression, education, and research. Text-to-image systems such as DALL.E, Stable Diffusion, and Midjourney can now convert ideas into visuals within seconds, but they also present a dual-use dilemma, raising critical ethical concerns: amplifying societal biases, producing high-fidelity disinformation, and violating intellectual property. This paper introduces SafeGen, a framework that embeds ethical safeguards directly into the text-to-image generation pipeline, grounding its design in established pri",
      "resume_fr": "Generative Artificial Intelligence (AI) has created unprecedented opportunities for creative expression, education, and research. Text-to-image systems such as DALL.E, Stable Diffusion, and Midjourney can now convert ideas into visuals within seconds, but they also present a dual-use dilemma, raising critical ethical concerns: amplifying societal biases, producing high-fidelity disinformation, and violating intellectual property. This paper introduces SafeGen, a framework that embeds ethical safeguards directly into the text-to-image generation pipeline, grounding its design in established pri",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Teaching Spell Checkers to Teach: Pedagogical Program Synthesis for Interactive Learning",
      "url": "https://arxiv.org/abs/2512.12115v1",
      "source": "arXiv – cs.HC + education",
      "published": "2025-12-13T01:16:54.000Z",
      "score": 85,
      "summary_en": "Spelling taught through memorization often fails many learners, particularly children with language-based learning disorders who struggle with the phonological skills necessary to spell words accurately. Educators such as speech-language pathologists (SLPs) address this instructional gap by using an inquiry-based approach to teach spelling that targets the phonology, morphology, meaning, and etymology of words. Yet, these strategies rarely appear in everyday writing tools, which simply detect and autocorrect errors. We introduce SPIRE (Spelling Inquiry Engine), a spell check system that brings",
      "summary_fr": "Spelling taught through memorization often fails many learners, particularly children with language-based learning disorders who struggle with the phonological skills necessary to spell words accurately. Educators such as speech-language pathologists (SLPs) address this instructional gap by using an inquiry-based approach to teach spelling that targets the phonology, morphology, meaning, and etymology of words. Yet, these strategies rarely appear in everyday writing tools, which simply detect and autocorrect errors. We introduce SPIRE (Spelling Inquiry Engine), a spell check system that brings",
      "resume_fr": "Spelling taught through memorization often fails many learners, particularly children with language-based learning disorders who struggle with the phonological skills necessary to spell words accurately. Educators such as speech-language pathologists (SLPs) address this instructional gap by using an inquiry-based approach to teach spelling that targets the phonology, morphology, meaning, and etymology of words. Yet, these strategies rarely appear in everyday writing tools, which simply detect and autocorrect errors. We introduce SPIRE (Spelling Inquiry Engine), a spell check system that brings",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "A General Algorithm for Detecting Higher-Order Interactions via Random Sequential Additions",
      "url": "https://arxiv.org/abs/2512.11793v1",
      "source": "arXiv – cs.LG + learning analytics",
      "published": "2025-12-12T18:57:29.000Z",
      "score": 70,
      "summary_en": "Many systems exhibit complex interactions between their components: some features or actions amplify each other's effects, others provide redundant information, and some contribute independently. We present a simple geometric method for discovering interactions and redundancies: when elements are added in random sequential orders and their contributions plotted over many trials, characteristic L-shaped patterns emerge that directly reflect interaction structure. The approach quantifies how the contribution of each element depends on those added before it, revealing patterns that distinguish in",
      "summary_fr": "Many systems exhibit complex interactions between their components: some features or actions amplify each other's effects, others provide redundant information, and some contribute independently. We present a simple geometric method for discovering interactions and redundancies: when elements are added in random sequential orders and their contributions plotted over many trials, characteristic L-shaped patterns emerge that directly reflect interaction structure. The approach quantifies how the contribution of each element depends on those added before it, revealing patterns that distinguish in",
      "resume_fr": "Many systems exhibit complex interactions between their components: some features or actions amplify each other's effects, others provide redundant information, and some contribute independently. We present a simple geometric method for discovering interactions and redundancies: when elements are added in random sequential orders and their contributions plotted over many trials, characteristic L-shaped patterns emerge that directly reflect interaction structure. The approach quantifies how the contribution of each element depends on those added before it, revealing patterns that distinguish in",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "SUMFORU: An LLM-Based Review Summarization Framework for Personalized Purchase Decision Support",
      "url": "https://arxiv.org/abs/2512.11755v1",
      "source": "arXiv – cs.CL (NLP/LLM)",
      "published": "2025-12-12T18:05:52.000Z",
      "score": 70,
      "summary_en": "Online product reviews contain rich but noisy signals that overwhelm users and hinder effective decision-making. Existing LLM-based summarizers remain generic and fail to account for individual preferences, limiting their practical utility. We propose SUMFORU, a steerable review summarization framework that aligns outputs with explicit user personas to support personalized purchase decisions. Our approach integrates a high-quality data pipeline built from the Amazon 2023 Review Dataset with a two-stage alignment procedure: (1) persona-aware Supervised Fine-Tuning (SFT) via asymmetric knowledge",
      "summary_fr": "Online product reviews contain rich but noisy signals that overwhelm users and hinder effective decision-making. Existing LLM-based summarizers remain generic and fail to account for individual preferences, limiting their practical utility. We propose SUMFORU, a steerable review summarization framework that aligns outputs with explicit user personas to support personalized purchase decisions. Our approach integrates a high-quality data pipeline built from the Amazon 2023 Review Dataset with a two-stage alignment procedure: (1) persona-aware Supervised Fine-Tuning (SFT) via asymmetric knowledge",
      "resume_fr": "Online product reviews contain rich but noisy signals that overwhelm users and hinder effective decision-making. Existing LLM-based summarizers remain generic and fail to account for individual preferences, limiting their practical utility. We propose SUMFORU, a steerable review summarization framework that aligns outputs with explicit user personas to support personalized purchase decisions. Our approach integrates a high-quality data pipeline built from the Amazon 2023 Review Dataset with a two-stage alignment procedure: (1) persona-aware Supervised Fine-Tuning (SFT) via asymmetric knowledge",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "From Signal to Turn: Interactional Friction in Modular Speech-to-Speech Pipelines",
      "url": "https://arxiv.org/abs/2512.11724v1",
      "source": "arXiv – cs.CL (NLP/LLM)",
      "published": "2025-12-12T17:05:11.000Z",
      "score": 70,
      "summary_en": "While voice-based AI systems have achieved remarkable generative capabilities, their interactions often feel conversationally broken. This paper examines the interactional friction that emerges in modular Speech-to-Speech Retrieval-Augmented Generation (S2S-RAG) pipelines. By analyzing a representative production system, we move beyond simple latency metrics to identify three recurring patterns of conversational breakdown: (1) Temporal Misalignment, where system delays violate user expectations of conversational rhythm; (2) Expressive Flattening, where the loss of paralinguistic cues leads to ",
      "summary_fr": "While voice-based AI systems have achieved remarkable generative capabilities, their interactions often feel conversationally broken. This paper examines the interactional friction that emerges in modular Speech-to-Speech Retrieval-Augmented Generation (S2S-RAG) pipelines. By analyzing a representative production system, we move beyond simple latency metrics to identify three recurring patterns of conversational breakdown: (1) Temporal Misalignment, where system delays violate user expectations of conversational rhythm; (2) Expressive Flattening, where the loss of paralinguistic cues leads to ",
      "resume_fr": "While voice-based AI systems have achieved remarkable generative capabilities, their interactions often feel conversationally broken. This paper examines the interactional friction that emerges in modular Speech-to-Speech Retrieval-Augmented Generation (S2S-RAG) pipelines. By analyzing a representative production system, we move beyond simple latency metrics to identify three recurring patterns of conversational breakdown: (1) Temporal Misalignment, where system delays violate user expectations of conversational rhythm; (2) Expressive Flattening, where the loss of paralinguistic cues leads to ",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Automating Historical Insight Extraction from Large-Scale Newspaper Archives via Neural Topic Modeling",
      "url": "https://arxiv.org/abs/2512.11635v1",
      "source": "arXiv – cs.CL (NLP/LLM)",
      "published": "2025-12-12T15:15:02.000Z",
      "score": 70,
      "summary_en": "Extracting coherent and human-understandable themes from large collections of unstructured historical newspaper archives presents significant challenges due to topic evolution, Optical Character Recognition (OCR) noise, and the sheer volume of text. Traditional topic-modeling methods, such as Latent Dirichlet Allocation (LDA), often fall short in capturing the complexity and dynamic nature of discourse in historical texts. To address these limitations, we employ BERTopic. This neural topic-modeling approach leverages transformerbased embeddings to extract and classify topics, which, despite it",
      "summary_fr": "Extracting coherent and human-understandable themes from large collections of unstructured historical newspaper archives presents significant challenges due to topic evolution, Optical Character Recognition (OCR) noise, and the sheer volume of text. Traditional topic-modeling methods, such as Latent Dirichlet Allocation (LDA), often fall short in capturing the complexity and dynamic nature of discourse in historical texts. To address these limitations, we employ BERTopic. This neural topic-modeling approach leverages transformerbased embeddings to extract and classify topics, which, despite it",
      "resume_fr": "Extracting coherent and human-understandable themes from large collections of unstructured historical newspaper archives presents significant challenges due to topic evolution, Optical Character Recognition (OCR) noise, and the sheer volume of text. Traditional topic-modeling methods, such as Latent Dirichlet Allocation (LDA), often fall short in capturing the complexity and dynamic nature of discourse in historical texts. To address these limitations, we employ BERTopic. This neural topic-modeling approach leverages transformerbased embeddings to extract and classify topics, which, despite it",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "AI Benchmark Democratization and Carpentry",
      "url": "https://arxiv.org/abs/2512.11588v1",
      "source": "arXiv – cs.AI + education/MOOC",
      "published": "2025-12-12T14:20:05.000Z",
      "score": 50,
      "summary_en": "Benchmarks are a cornerstone of modern machine learning, enabling reproducibility, comparison, and scientific progress. However, AI benchmarks are increasingly complex, requiring dynamic, AI-focused workflows. Rapid evolution in model architectures, scale, datasets, and deployment contexts makes evaluation a moving target. Large language models often memorize static benchmarks, causing a gap between benchmark results and real-world performance. Beyond traditional static benchmarks, continuous adaptive benchmarking frameworks are needed to align scientific assessment with deployment risks. This",
      "summary_fr": "Benchmarks are a cornerstone of modern machine learning, enabling reproducibility, comparison, and scientific progress. However, AI benchmarks are increasingly complex, requiring dynamic, AI-focused workflows. Rapid evolution in model architectures, scale, datasets, and deployment contexts makes evaluation a moving target. Large language models often memorize static benchmarks, causing a gap between benchmark results and real-world performance. Beyond traditional static benchmarks, continuous adaptive benchmarking frameworks are needed to align scientific assessment with deployment risks. This",
      "resume_fr": "Benchmarks are a cornerstone of modern machine learning, enabling reproducibility, comparison, and scientific progress. However, AI benchmarks are increasingly complex, requiring dynamic, AI-focused workflows. Rapid evolution in model architectures, scale, datasets, and deployment contexts makes evaluation a moving target. Large language models often memorize static benchmarks, causing a gap between benchmark results and real-world performance. Beyond traditional static benchmarks, continuous adaptive benchmarking frameworks are needed to align scientific assessment with deployment risks. This",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Campuses Are Transforming Student and Academic Spaces for Real Impact",
      "url": "https://edtechmagazine.com/higher/article/2025/12/campuses-are-transforming-student-and-academic-spaces-real-impact",
      "source": "EdTech Magazine (Higher Ed)",
      "published": "2025-12-11T21:25:45.000Z",
      "score": 65,
      "summary_en": "When I walk through today’s campuses, I’m reminded that students aren’t just looking for an education, they’re looking for an experience. They want spaces that support how they live, learn, collaborate and dream. That’s why the modernization of student and academic spaces isn’t just a facilities project -- it’s a student success initiative. At CDW, we work with institutions that are rethinking what campus life should feel like. The goal? Create environments that are so intuitive and tech-enabled, students barely notice the systems at work because everything just works. Modernizing for a…",
      "summary_fr": "When I walk through today’s campuses, I’m reminded that students aren’t just looking for an education, they’re looking for an experience. They want spaces that support how they live, learn, collaborate and dream. That’s why the modernization of student and academic spaces isn’t just a facilities project -- it’s a student success initiative. At CDW, we work with institutions that are rethinking what campus life should feel like. The goal? Create environments that are so intuitive and tech-enabled, students barely notice the systems at work because everything just works. Modernizing for a…",
      "resume_fr": "When I walk through today’s campuses, I’m reminded that students aren’t just looking for an education, they’re looking for an experience. They want spaces that support how they live, learn, collaborate and dream. That’s why the modernization of student and academic spaces isn’t just a facilities project -- it’s a student success initiative. At CDW, we work with institutions that are rethinking what campus life should feel like. The goal? Create environments that are so intuitive and tech-enabled, students barely notice the systems at work because everything just works. Modernizing for a…",
      "tags": [],
      "breakdown": {
        "research": 0,
        "policy": 35,
        "institution": 15,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=0, Politiques=35, Institution=15, Impact=15.",
      "image": "https://edtechmagazine.com/higher/sites/edtechmagazine.com.higher/files/styles/cdw_hero/public/articles/%5Bcdw_tech_site%3Afield_site_shortname%5D/202512/GettyImages-597957846.jpg?itok=rz_ykYFI"
    },
    {
      "title": "ImplicitRDP: An End-to-End Visual-Force Diffusion Policy with Structural Slow-Fast Learning",
      "url": "https://arxiv.org/abs/2512.10946v1",
      "source": "arXiv – cs.LG + learning analytics",
      "published": "2025-12-11T18:59:46.000Z",
      "score": 70,
      "summary_en": "Human-level contact-rich manipulation relies on the distinct roles of two key modalities: vision provides spatially rich but temporally slow global context, while force sensing captures rapid, high-frequency local contact dynamics. Integrating these signals is challenging due to their fundamental frequency and informational disparities. In this work, we propose ImplicitRDP, a unified end-to-end visual-force diffusion policy that integrates visual planning and reactive force control within a single network. We introduce Structural Slow-Fast Learning, a mechanism utilizing causal attention to si",
      "summary_fr": "Human-level contact-rich manipulation relies on the distinct roles of two key modalities: vision provides spatially rich but temporally slow global context, while force sensing captures rapid, high-frequency local contact dynamics. Integrating these signals is challenging due to their fundamental frequency and informational disparities. In this work, we propose ImplicitRDP, a unified end-to-end visual-force diffusion policy that integrates visual planning and reactive force control within a single network. We introduce Structural Slow-Fast Learning, a mechanism utilizing causal attention to si",
      "resume_fr": "Human-level contact-rich manipulation relies on the distinct roles of two key modalities: vision provides spatially rich but temporally slow global context, while force sensing captures rapid, high-frequency local contact dynamics. Integrating these signals is challenging due to their fundamental frequency and informational disparities. In this work, we propose ImplicitRDP, a unified end-to-end visual-force diffusion policy that integrates visual planning and reactive force control within a single network. We introduce Structural Slow-Fast Learning, a mechanism utilizing causal attention to si",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Stronger Normalization-Free Transformers",
      "url": "https://arxiv.org/abs/2512.10938v1",
      "source": "arXiv – cs.LG + learning analytics",
      "published": "2025-12-11T18:58:49.000Z",
      "score": 50,
      "summary_en": "Although normalization layers have long been viewed as indispensable components of deep learning architectures, the recent introduction of Dynamic Tanh (DyT) has demonstrated that alternatives are possible. The point-wise function DyT constrains extreme values for stable convergence and reaches normalization-level performance; this work seeks further for function designs that can surpass it. We first study how the intrinsic properties of point-wise functions influence training and performance. Building on these findings, we conduct a large-scale search for a more effective function design. Thr",
      "summary_fr": "Although normalization layers have long been viewed as indispensable components of deep learning architectures, the recent introduction of Dynamic Tanh (DyT) has demonstrated that alternatives are possible. The point-wise function DyT constrains extreme values for stable convergence and reaches normalization-level performance; this work seeks further for function designs that can surpass it. We first study how the intrinsic properties of point-wise functions influence training and performance. Building on these findings, we conduct a large-scale search for a more effective function design. Thr",
      "resume_fr": "Although normalization layers have long been viewed as indispensable components of deep learning architectures, the recent introduction of Dynamic Tanh (DyT) has demonstrated that alternatives are possible. The point-wise function DyT constrains extreme values for stable convergence and reaches normalization-level performance; this work seeks further for function designs that can surpass it. We first study how the intrinsic properties of point-wise functions influence training and performance. Building on these findings, we conduct a large-scale search for a more effective function design. Thr",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 15,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=15, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Asynchronous Reasoning: Training-Free Interactive Thinking LLMs",
      "url": "https://arxiv.org/abs/2512.10931v1",
      "source": "arXiv – cs.CL (NLP/LLM)",
      "published": "2025-12-11T18:57:02.000Z",
      "score": 70,
      "summary_en": "Many state-of-the-art LLMs are trained to think before giving their answer. Reasoning can greatly improve language model capabilities and safety, but it also makes them less interactive: given a new input, a model must stop thinking before it can respond. Real-world use cases such as voice-based or embedded assistants require an LLM agent to respond and adapt to additional information in real time, which is incompatible with sequential interactions. In contrast, humans can listen, think, and act asynchronously: we begin thinking about the problem while reading it and continue thinking while fo",
      "summary_fr": "Many state-of-the-art LLMs are trained to think before giving their answer. Reasoning can greatly improve language model capabilities and safety, but it also makes them less interactive: given a new input, a model must stop thinking before it can respond. Real-world use cases such as voice-based or embedded assistants require an LLM agent to respond and adapt to additional information in real time, which is incompatible with sequential interactions. In contrast, humans can listen, think, and act asynchronously: we begin thinking about the problem while reading it and continue thinking while fo",
      "resume_fr": "Many state-of-the-art LLMs are trained to think before giving their answer. Reasoning can greatly improve language model capabilities and safety, but it also makes them less interactive: given a new input, a model must stop thinking before it can respond. Real-world use cases such as voice-based or embedded assistants require an LLM agent to respond and adapt to additional information in real time, which is incompatible with sequential interactions. In contrast, humans can listen, think, and act asynchronously: we begin thinking about the problem while reading it and continue thinking while fo",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "CompanionCast: A Multi-Agent Conversational AI Framework with Spatial Audio for Social Co-Viewing Experiences",
      "url": "https://arxiv.org/abs/2512.10918v1",
      "source": "arXiv – cs.HC + education",
      "published": "2025-12-11T18:44:44.000Z",
      "score": 85,
      "summary_en": "Social presence is central to the enjoyment of watching content together, yet modern media consumption is increasingly solitary. We investigate whether multi-agent conversational AI systems can recreate the dynamics of shared viewing experiences across diverse content types. We present CompanionCast, a general framework for orchestrating multiple role-specialized AI agents that respond to video content using multimodal inputs, speech synthesis, and spatial audio. Distinctly, CompanionCast integrates an LLM-as-a-Judge module that iteratively scores and refines conversations across five dimensio",
      "summary_fr": "Social presence is central to the enjoyment of watching content together, yet modern media consumption is increasingly solitary. We investigate whether multi-agent conversational AI systems can recreate the dynamics of shared viewing experiences across diverse content types. We present CompanionCast, a general framework for orchestrating multiple role-specialized AI agents that respond to video content using multimodal inputs, speech synthesis, and spatial audio. Distinctly, CompanionCast integrates an LLM-as-a-Judge module that iteratively scores and refines conversations across five dimensio",
      "resume_fr": "Social presence is central to the enjoyment of watching content together, yet modern media consumption is increasingly solitary. We investigate whether multi-agent conversational AI systems can recreate the dynamics of shared viewing experiences across diverse content types. We present CompanionCast, a general framework for orchestrating multiple role-specialized AI agents that respond to video content using multimodal inputs, speech synthesis, and spatial audio. Distinctly, CompanionCast integrates an LLM-as-a-Judge module that iteratively scores and refines conversations across five dimensio",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "LabelFusion: Learning to Fuse LLMs and Transformer Classifiers for Robust Text Classification",
      "url": "https://arxiv.org/abs/2512.10793v1",
      "source": "arXiv – cs.CL (NLP/LLM)",
      "published": "2025-12-11T16:39:07.000Z",
      "score": 50,
      "summary_en": "LabelFusion is a fusion ensemble for text classification that learns to combine a traditional transformer-based classifier (e.g., RoBERTa) with one or more Large Language Models (LLMs such as OpenAI GPT, Google Gemini, or DeepSeek) to deliver accurate and cost-aware predictions across multi-class and multi-label tasks. The package provides a simple high-level interface (AutoFusionClassifier) that trains the full pipeline end-to-end with minimal configuration, and a flexible API for advanced users. Under the hood, LabelFusion integrates vector signals from both sources by concatenating the ML b",
      "summary_fr": "LabelFusion is a fusion ensemble for text classification that learns to combine a traditional transformer-based classifier (e.g., RoBERTa) with one or more Large Language Models (LLMs such as OpenAI GPT, Google Gemini, or DeepSeek) to deliver accurate and cost-aware predictions across multi-class and multi-label tasks. The package provides a simple high-level interface (AutoFusionClassifier) that trains the full pipeline end-to-end with minimal configuration, and a flexible API for advanced users. Under the hood, LabelFusion integrates vector signals from both sources by concatenating the ML b",
      "resume_fr": "LabelFusion is a fusion ensemble for text classification that learns to combine a traditional transformer-based classifier (e.g., RoBERTa) with one or more Large Language Models (LLMs such as OpenAI GPT, Google Gemini, or DeepSeek) to deliver accurate and cost-aware predictions across multi-class and multi-label tasks. The package provides a simple high-level interface (AutoFusionClassifier) that trains the full pipeline end-to-end with minimal configuration, and a flexible API for advanced users. Under the hood, LabelFusion integrates vector signals from both sources by concatenating the ML b",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 15,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=15, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Opportunities and Challenges in Harnessing Digital Technology for Effective Teaching and Learning",
      "url": "https://arxiv.org/abs/2512.10777v1",
      "source": "arXiv – cs.HC + education",
      "published": "2025-12-11T16:13:33.000Z",
      "score": 65,
      "summary_en": "Most of today's educators are in no shortage of digital and online learning technologies available at their fingertips, ranging from Learning Management Systems such as Canvas, Blackboard, or Moodle, online meeting tools, online homework, and tutoring systems, exam proctoring platforms, computer simulations, and even virtual reality/augmented reality technologies. Furthermore, with the rapid development and wide availability of generative artificial intelligence (GenAI) services such as ChatGPT, we are just at the beginning of harnessing their potential to transform higher education. Yet, faci",
      "summary_fr": "Most of today's educators are in no shortage of digital and online learning technologies available at their fingertips, ranging from Learning Management Systems such as Canvas, Blackboard, or Moodle, online meeting tools, online homework, and tutoring systems, exam proctoring platforms, computer simulations, and even virtual reality/augmented reality technologies. Furthermore, with the rapid development and wide availability of generative artificial intelligence (GenAI) services such as ChatGPT, we are just at the beginning of harnessing their potential to transform higher education. Yet, faci",
      "resume_fr": "Most of today's educators are in no shortage of digital and online learning technologies available at their fingertips, ranging from Learning Management Systems such as Canvas, Blackboard, or Moodle, online meeting tools, online homework, and tutoring systems, exam proctoring platforms, computer simulations, and even virtual reality/augmented reality technologies. Furthermore, with the rapid development and wide availability of generative artificial intelligence (GenAI) services such as ChatGPT, we are just at the beginning of harnessing their potential to transform higher education. Yet, faci",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 15,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=15, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Designing AI-Resilient Assessments Using Interconnected Problems: A Theoretically Grounded and Empirically Validated Framework",
      "url": "https://arxiv.org/abs/2512.10758v1",
      "source": "arXiv – cs.AI + education/MOOC",
      "published": "2025-12-11T15:53:19.000Z",
      "score": 85,
      "summary_en": "The rapid adoption of generative AI has undermined traditional modular assessments in computing education, creating a disconnect between academic evaluation and industry practice. This paper presents a theoretically grounded framework for designing AI-resilient assessments, supported by formal analysis and multi-year empirical validation. We make three contributions. First, we establish two theoretical results: (1) assessments composed of interconnected problems, where outputs feed into subsequent stages, are more AI-resilient than modular assessments because current language models struggle w",
      "summary_fr": "The rapid adoption of generative AI has undermined traditional modular assessments in computing education, creating a disconnect between academic evaluation and industry practice. This paper presents a theoretically grounded framework for designing AI-resilient assessments, supported by formal analysis and multi-year empirical validation. We make three contributions. First, we establish two theoretical results: (1) assessments composed of interconnected problems, where outputs feed into subsequent stages, are more AI-resilient than modular assessments because current language models struggle w",
      "resume_fr": "The rapid adoption of generative AI has undermined traditional modular assessments in computing education, creating a disconnect between academic evaluation and industry practice. This paper presents a theoretically grounded framework for designing AI-resilient assessments, supported by formal analysis and multi-year empirical validation. We make three contributions. First, we establish two theoretical results: (1) assessments composed of interconnected problems, where outputs feed into subsequent stages, are more AI-resilient than modular assessments because current language models struggle w",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Two New AI Ethics Certifications Available from IEEE",
      "url": "https://spectrum.ieee.org/two-new-ai-ethics-certifications",
      "source": "IEEE Spectrum – AI",
      "published": "2025-12-10T19:00:02.000Z",
      "score": 70,
      "summary_en": "It appears that nearly every organization is planning to use artificial intelligence to improve operations. Although autonomous intelligent systems (AIS) can offer significant benefits, they also can be used unethically. The technology can create deepfakes, realistic-looking altered images and videos that help spread misinformation and disinformation. Meanwhile, AI systems trained on biased data can perpetuate discrimination in hiring, lending, and other practices. And surveillance systems that incorporate AI can lead to misidentification. Those issues have led to concerns about AIS trustworth",
      "summary_fr": "It appears that nearly every organization is planning to use artificial intelligence to improve operations. Although autonomous intelligent systems (AIS) can offer significant benefits, they also can be used unethically. The technology can create deepfakes, realistic-looking altered images and videos that help spread misinformation and disinformation. Meanwhile, AI systems trained on biased data can perpetuate discrimination in hiring, lending, and other practices. And surveillance systems that incorporate AI can lead to misidentification. Those issues have led to concerns about AIS trustworth",
      "resume_fr": "It appears that nearly every organization is planning to use artificial intelligence to improve operations. Although autonomous intelligent systems (AIS) can offer significant benefits, they also can be used unethically. The technology can create deepfakes, realistic-looking altered images and videos that help spread misinformation and disinformation. Meanwhile, AI systems trained on biased data can perpetuate discrimination in hiring, lending, and other practices. And surveillance systems that incorporate AI can lead to misidentification. Those issues have led to concerns about AIS trustworth",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=0.",
      "image": "https://spectrum.ieee.org/media-library/a-large-floating-cube-with-ai-written-on-its-front-and-a-halo-hovering-above.jpg?id=62301657&width=1200&height=600&coordinates=0%2C250%2C0%2C250"
    },
    {
      "title": "STACHE: Local Black-Box Explanations for Reinforcement Learning Policies",
      "url": "https://arxiv.org/abs/2512.09909v1",
      "source": "arXiv – cs.LG + learning analytics",
      "published": "2025-12-10T18:37:28.000Z",
      "score": 50,
      "summary_en": "Reinforcement learning agents often behave unexpectedly in sparse-reward or safety-critical environments, creating a strong need for reliable debugging and verification tools. In this paper, we propose STACHE, a comprehensive framework for generating local, black-box explanations for an agent's specific action within discrete Markov games. Our method produces a Composite Explanation consisting of two complementary components: (1) a Robustness Region, the connected neighborhood of states where the agent's action remains invariant, and (2) Minimal Counterfactuals, the smallest state perturbation",
      "summary_fr": "Reinforcement learning agents often behave unexpectedly in sparse-reward or safety-critical environments, creating a strong need for reliable debugging and verification tools. In this paper, we propose STACHE, a comprehensive framework for generating local, black-box explanations for an agent's specific action within discrete Markov games. Our method produces a Composite Explanation consisting of two complementary components: (1) a Robustness Region, the connected neighborhood of states where the agent's action remains invariant, and (2) Minimal Counterfactuals, the smallest state perturbation",
      "resume_fr": "Reinforcement learning agents often behave unexpectedly in sparse-reward or safety-critical environments, creating a strong need for reliable debugging and verification tools. In this paper, we propose STACHE, a comprehensive framework for generating local, black-box explanations for an agent's specific action within discrete Markov games. Our method produces a Composite Explanation consisting of two complementary components: (1) a Robustness Region, the connected neighborhood of states where the agent's action remains invariant, and (2) Minimal Counterfactuals, the smallest state perturbation",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 15,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=15, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "SCOPE: Language Models as One-Time Teacher for Hierarchical Planning in Text Environments",
      "url": "https://arxiv.org/abs/2512.09897v1",
      "source": "arXiv – cs.CL (NLP/LLM)",
      "published": "2025-12-10T18:26:14.000Z",
      "score": 50,
      "summary_en": "Long-term planning in complex, text-based environments presents significant challenges due to open-ended action spaces, ambiguous observations, and sparse feedback. Recent research suggests that large language models (LLMs) encode rich semantic knowledge about the world, which can be valuable for guiding agents in high-level reasoning and planning across both embodied and purely textual settings. However, existing approaches often depend heavily on querying LLMs during training and inference, making them computationally expensive and difficult to deploy efficiently. In addition, these methods ",
      "summary_fr": "Long-term planning in complex, text-based environments presents significant challenges due to open-ended action spaces, ambiguous observations, and sparse feedback. Recent research suggests that large language models (LLMs) encode rich semantic knowledge about the world, which can be valuable for guiding agents in high-level reasoning and planning across both embodied and purely textual settings. However, existing approaches often depend heavily on querying LLMs during training and inference, making them computationally expensive and difficult to deploy efficiently. In addition, these methods ",
      "resume_fr": "Long-term planning in complex, text-based environments presents significant challenges due to open-ended action spaces, ambiguous observations, and sparse feedback. Recent research suggests that large language models (LLMs) encode rich semantic knowledge about the world, which can be valuable for guiding agents in high-level reasoning and planning across both embodied and purely textual settings. However, existing approaches often depend heavily on querying LLMs during training and inference, making them computationally expensive and difficult to deploy efficiently. In addition, these methods ",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Analysis of Dirichlet Energies as Over-smoothing Measures",
      "url": "https://arxiv.org/abs/2512.09890v1",
      "source": "arXiv – cs.LG + learning analytics",
      "published": "2025-12-10T18:17:33.000Z",
      "score": 50,
      "summary_en": "We analyze the distinctions between two functionals often used as over-smoothing measures: the Dirichlet energies induced by the unnormalized graph Laplacian and the normalized graph Laplacian. We demonstrate that the latter fails to satisfy the axiomatic definition of a node-similarity measure proposed by Rusch \\textit{et al.} By formalizing fundamental spectral properties of these two definitions, we highlight critical distinctions necessary to select the metric that is spectrally compatible with the GNN architecture, thereby resolving ambiguities in monitoring the dynamics.",
      "summary_fr": "We analyze the distinctions between two functionals often used as over-smoothing measures: the Dirichlet energies induced by the unnormalized graph Laplacian and the normalized graph Laplacian. We demonstrate that the latter fails to satisfy the axiomatic definition of a node-similarity measure proposed by Rusch \\textit{et al.} By formalizing fundamental spectral properties of these two definitions, we highlight critical distinctions necessary to select the metric that is spectrally compatible with the GNN architecture, thereby resolving ambiguities in monitoring the dynamics.",
      "resume_fr": "We analyze the distinctions between two functionals often used as over-smoothing measures: the Dirichlet energies induced by the unnormalized graph Laplacian and the normalized graph Laplacian. We demonstrate that the latter fails to satisfy the axiomatic definition of a node-similarity measure proposed by Rusch \\textit{et al.} By formalizing fundamental spectral properties of these two definitions, we highlight critical distinctions necessary to select the metric that is spectrally compatible with the GNN architecture, thereby resolving ambiguities in monitoring the dynamics.",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 15,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=15, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Astra: General Interactive World Model with Autoregressive Denoising",
      "url": "https://arxiv.org/abs/2512.08931v1",
      "source": "arXiv – cs.LG + learning analytics",
      "published": "2025-12-09T18:59:57.000Z",
      "score": 70,
      "summary_en": "Recent advances in diffusion transformers have empowered video generation models to generate high-quality video clips from texts or images. However, world models with the ability to predict long-horizon futures from past observations and actions remain underexplored, especially for general-purpose scenarios and various forms of actions. To bridge this gap, we introduce Astra, an interactive general world model that generates real-world futures for diverse scenarios (e.g., autonomous driving, robot grasping) with precise action interactions (e.g., camera motion, robot action). We propose an aut",
      "summary_fr": "Recent advances in diffusion transformers have empowered video generation models to generate high-quality video clips from texts or images. However, world models with the ability to predict long-horizon futures from past observations and actions remain underexplored, especially for general-purpose scenarios and various forms of actions. To bridge this gap, we introduce Astra, an interactive general world model that generates real-world futures for diverse scenarios (e.g., autonomous driving, robot grasping) with precise action interactions (e.g., camera motion, robot action). We propose an aut",
      "resume_fr": "Recent advances in diffusion transformers have empowered video generation models to generate high-quality video clips from texts or images. However, world models with the ability to predict long-horizon futures from past observations and actions remain underexplored, especially for general-purpose scenarios and various forms of actions. To bridge this gap, we introduce Astra, an interactive general world model that generates real-world futures for diverse scenarios (e.g., autonomous driving, robot grasping) with precise action interactions (e.g., camera motion, robot action). We propose an aut",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "OSMO: Open-Source Tactile Glove for Human-to-Robot Skill Transfer",
      "url": "https://arxiv.org/abs/2512.08920v1",
      "source": "arXiv – cs.LG + learning analytics",
      "published": "2025-12-09T18:56:30.000Z",
      "score": 85,
      "summary_en": "Human video demonstrations provide abundant training data for learning robot policies, but video alone cannot capture the rich contact signals critical for mastering manipulation. We introduce OSMO, an open-source wearable tactile glove designed for human-to-robot skill transfer. The glove features 12 three-axis tactile sensors across the fingertips and palm and is designed to be compatible with state-of-the-art hand-tracking methods for in-the-wild data collection. We demonstrate that a robot policy trained exclusively on human demonstrations collected with OSMO, without any real robot data, ",
      "summary_fr": "Human video demonstrations provide abundant training data for learning robot policies, but video alone cannot capture the rich contact signals critical for mastering manipulation. We introduce OSMO, an open-source wearable tactile glove designed for human-to-robot skill transfer. The glove features 12 three-axis tactile sensors across the fingertips and palm and is designed to be compatible with state-of-the-art hand-tracking methods for in-the-wild data collection. We demonstrate that a robot policy trained exclusively on human demonstrations collected with OSMO, without any real robot data, ",
      "resume_fr": "Human video demonstrations provide abundant training data for learning robot policies, but video alone cannot capture the rich contact signals critical for mastering manipulation. We introduce OSMO, an open-source wearable tactile glove designed for human-to-robot skill transfer. The glove features 12 three-axis tactile sensors across the fingertips and palm and is designed to be compatible with state-of-the-art hand-tracking methods for in-the-wild data collection. We demonstrate that a robot policy trained exclusively on human demonstrations collected with OSMO, without any real robot data, ",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 15,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=15, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Revisiting the Scaling Properties of Downstream Metrics in Large Language Model Training",
      "url": "https://arxiv.org/abs/2512.08894v1",
      "source": "arXiv – cs.LG + learning analytics",
      "published": "2025-12-09T18:33:48.000Z",
      "score": 50,
      "summary_en": "While scaling laws for Large Language Models (LLMs) traditionally focus on proxy metrics like pretraining loss, predicting downstream task performance has been considered unreliable. This paper challenges that view by proposing a direct framework to model the scaling of benchmark performance from the training budget. We find that for a fixed token-to-parameter ratio, a simple power law can accurately describe the scaling behavior of log accuracy on multiple popular downstream tasks. Our results show that the direct approach extrapolates better than the previously proposed two-stage procedure, ",
      "summary_fr": "While scaling laws for Large Language Models (LLMs) traditionally focus on proxy metrics like pretraining loss, predicting downstream task performance has been considered unreliable. This paper challenges that view by proposing a direct framework to model the scaling of benchmark performance from the training budget. We find that for a fixed token-to-parameter ratio, a simple power law can accurately describe the scaling behavior of log accuracy on multiple popular downstream tasks. Our results show that the direct approach extrapolates better than the previously proposed two-stage procedure, ",
      "resume_fr": "While scaling laws for Large Language Models (LLMs) traditionally focus on proxy metrics like pretraining loss, predicting downstream task performance has been considered unreliable. This paper challenges that view by proposing a direct framework to model the scaling of benchmark performance from the training budget. We find that for a fixed token-to-parameter ratio, a simple power law can accurately describe the scaling behavior of log accuracy on multiple popular downstream tasks. Our results show that the direct approach extrapolates better than the previously proposed two-stage procedure, ",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 15,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=15, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Examining Student Interactions with a Pedagogical AI-Assistant for Essay Writing and their Impact on Students Writing Quality",
      "url": "https://arxiv.org/abs/2512.08596v1",
      "source": "arXiv – cs.AI + education/MOOC",
      "published": "2025-12-09T13:34:33.000Z",
      "score": 85,
      "summary_en": "The dynamic nature of interactions between students and GenAI, as well as their relationship to writing quality, remains underexplored. While most research has examined how general-purpose GenAI can support writing, fewer studies have investigated how students interact with pedagogically designed systems across different phases of the writing process. To address this gap, we evaluated a GenAI-driven essay-writing assistant (EWA) designed to support higher education students in argumentative writing. Drawing on 1,282 interaction logs from 32 undergraduates during a two-hour writing session, Seq",
      "summary_fr": "The dynamic nature of interactions between students and GenAI, as well as their relationship to writing quality, remains underexplored. While most research has examined how general-purpose GenAI can support writing, fewer studies have investigated how students interact with pedagogically designed systems across different phases of the writing process. To address this gap, we evaluated a GenAI-driven essay-writing assistant (EWA) designed to support higher education students in argumentative writing. Drawing on 1,282 interaction logs from 32 undergraduates during a two-hour writing session, Seq",
      "resume_fr": "The dynamic nature of interactions between students and GenAI, as well as their relationship to writing quality, remains underexplored. While most research has examined how general-purpose GenAI can support writing, fewer studies have investigated how students interact with pedagogically designed systems across different phases of the writing process. To address this gap, we evaluated a GenAI-driven essay-writing assistant (EWA) designed to support higher education students in argumentative writing. Drawing on 1,282 interaction logs from 32 undergraduates during a two-hour writing session, Seq",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Disturbance-Free Surgical Video Generation from Multi-Camera Shadowless Lamps for Open Surgery",
      "url": "https://arxiv.org/abs/2512.08577v1",
      "source": "arXiv – cs.AI + education/MOOC",
      "published": "2025-12-09T13:15:32.000Z",
      "score": 50,
      "summary_en": "Video recordings of open surgeries are greatly required for education and research purposes. However, capturing unobstructed videos is challenging since surgeons frequently block the camera field of view. To avoid occlusion, the positions and angles of the camera must be frequently adjusted, which is highly labor-intensive. Prior work has addressed this issue by installing multiple cameras on a shadowless lamp and arranging them to fully surround the surgical area. This setup increases the chances of some cameras capturing an unobstructed view. However, manual image alignment is needed in post",
      "summary_fr": "Video recordings of open surgeries are greatly required for education and research purposes. However, capturing unobstructed videos is challenging since surgeons frequently block the camera field of view. To avoid occlusion, the positions and angles of the camera must be frequently adjusted, which is highly labor-intensive. Prior work has addressed this issue by installing multiple cameras on a shadowless lamp and arranging them to fully surround the surgical area. This setup increases the chances of some cameras capturing an unobstructed view. However, manual image alignment is needed in post",
      "resume_fr": "Video recordings of open surgeries are greatly required for education and research purposes. However, capturing unobstructed videos is challenging since surgeons frequently block the camera field of view. To avoid occlusion, the positions and angles of the camera must be frequently adjusted, which is highly labor-intensive. Prior work has addressed this issue by installing multiple cameras on a shadowless lamp and arranging them to fully surround the surgical area. This setup increases the chances of some cameras capturing an unobstructed view. However, manual image alignment is needed in post",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Gamification with Purpose: What Learners Prefer to Motivate Their Learning",
      "url": "https://arxiv.org/abs/2512.08551v1",
      "source": "arXiv – cs.HC + education",
      "published": "2025-12-09T12:47:13.000Z",
      "score": 50,
      "summary_en": "This study investigates learners' preferences for game design elements (GDEs) in educational contexts to inform the development of purpose-driven gamification strategies. It emphasizes a learner-centered approach that aligns gamification design with pedagogical goals, while mitigating risks such as the erosion of intrinsic motivation. A systematic literature review was conducted to identify ten widely discussed GDEs. Visual prototypes representing each element were developed, and a best-worst scaling (BWS) survey with 125 participants was administered to elicit preference rankings. Qualitative",
      "summary_fr": "This study investigates learners' preferences for game design elements (GDEs) in educational contexts to inform the development of purpose-driven gamification strategies. It emphasizes a learner-centered approach that aligns gamification design with pedagogical goals, while mitigating risks such as the erosion of intrinsic motivation. A systematic literature review was conducted to identify ten widely discussed GDEs. Visual prototypes representing each element were developed, and a best-worst scaling (BWS) survey with 125 participants was administered to elicit preference rankings. Qualitative",
      "resume_fr": "This study investigates learners' preferences for game design elements (GDEs) in educational contexts to inform the development of purpose-driven gamification strategies. It emphasizes a learner-centered approach that aligns gamification design with pedagogical goals, while mitigating risks such as the erosion of intrinsic motivation. A systematic literature review was conducted to identify ten widely discussed GDEs. Visual prototypes representing each element were developed, and a best-worst scaling (BWS) survey with 125 participants was administered to elicit preference rankings. Qualitative",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "DermETAS-SNA LLM: A Dermatology Focused Evolutionary Transformer Architecture Search with StackNet Augmented LLM Assistant",
      "url": "https://arxiv.org/abs/2512.08998v1",
      "source": "arXiv – cs.AI + education/MOOC",
      "published": "2025-12-09T00:37:12.000Z",
      "score": 65,
      "summary_en": "Our work introduces the DermETAS-SNA LLM Assistant that integrates Dermatology-focused Evolutionary Transformer Architecture Search with StackNet Augmented LLM. The assistant dynamically learns skin-disease classifiers and provides medically informed descriptions to facilitate clinician-patient interpretation. Contributions include: (1) Developed an ETAS framework on the SKINCON dataset to optimize a Vision Transformer (ViT) tailored for dermatological feature representation and then fine-tuned binary classifiers for each of the 23 skin disease categories in the DermNet dataset to enhance clas",
      "summary_fr": "Our work introduces the DermETAS-SNA LLM Assistant that integrates Dermatology-focused Evolutionary Transformer Architecture Search with StackNet Augmented LLM. The assistant dynamically learns skin-disease classifiers and provides medically informed descriptions to facilitate clinician-patient interpretation. Contributions include: (1) Developed an ETAS framework on the SKINCON dataset to optimize a Vision Transformer (ViT) tailored for dermatological feature representation and then fine-tuned binary classifiers for each of the 23 skin disease categories in the DermNet dataset to enhance clas",
      "resume_fr": "Our work introduces the DermETAS-SNA LLM Assistant that integrates Dermatology-focused Evolutionary Transformer Architecture Search with StackNet Augmented LLM. The assistant dynamically learns skin-disease classifiers and provides medically informed descriptions to facilitate clinician-patient interpretation. Contributions include: (1) Developed an ETAS framework on the SKINCON dataset to optimize a Vision Transformer (ViT) tailored for dermatological feature representation and then fine-tuned binary classifiers for each of the 23 skin disease categories in the DermNet dataset to enhance clas",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 15,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=15, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Actor–critic networks with analogue memristors mimicking reward-based learning",
      "url": "https://www.nature.com/articles/s42256-025-01149-w",
      "source": "Nature Machine Intelligence",
      "published": "2025-12-09T00:00:00.000Z",
      "score": 70,
      "summary_en": "",
      "summary_fr": "",
      "resume_fr": "",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=0.",
      "image": "https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fs42256-025-01149-w/MediaObjects/42256_2025_1149_Fig1_HTML.png"
    },
    {
      "title": "Large Language Models for Education and Research: An Empirical and User Survey-based Analysis",
      "url": "https://arxiv.org/abs/2512.08057v1",
      "source": "arXiv – cs.AI + education/MOOC",
      "published": "2025-12-08T21:35:28.000Z",
      "score": 50,
      "summary_en": "Pretrained Large Language Models (LLMs) have achieved remarkable success across diverse domains, with education and research emerging as particularly impactful areas. Among current state-of-the-art LLMs, ChatGPT and DeepSeek exhibit strong capabilities in mathematics, science, medicine, literature, and programming. In this study, we present a comprehensive evaluation of these two LLMs through background technology analysis, empirical experiments, and a real-world user survey. The evaluation explores trade-offs among model accuracy, computational efficiency, and user experience in educational a",
      "summary_fr": "Pretrained Large Language Models (LLMs) have achieved remarkable success across diverse domains, with education and research emerging as particularly impactful areas. Among current state-of-the-art LLMs, ChatGPT and DeepSeek exhibit strong capabilities in mathematics, science, medicine, literature, and programming. In this study, we present a comprehensive evaluation of these two LLMs through background technology analysis, empirical experiments, and a real-world user survey. The evaluation explores trade-offs among model accuracy, computational efficiency, and user experience in educational a",
      "resume_fr": "Pretrained Large Language Models (LLMs) have achieved remarkable success across diverse domains, with education and research emerging as particularly impactful areas. Among current state-of-the-art LLMs, ChatGPT and DeepSeek exhibit strong capabilities in mathematics, science, medicine, literature, and programming. In this study, we present a comprehensive evaluation of these two LLMs through background technology analysis, empirical experiments, and a real-world user survey. The evaluation explores trade-offs among model accuracy, computational efficiency, and user experience in educational a",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Automated Generation of Custom MedDRA Queries Using SafeTerm Medical Map",
      "url": "https://arxiv.org/abs/2512.07694v1",
      "source": "arXiv – cs.CL (NLP/LLM)",
      "published": "2025-12-08T16:33:03.000Z",
      "score": 50,
      "summary_en": "In pre-market drug safety review, grouping related adverse event terms into standardised MedDRA queries or the FDA Office of New Drugs Custom Medical Queries (OCMQs) is critical for signal detection. We present a novel quantitative artificial intelligence system that understands and processes medical terminology and automatically retrieves relevant MedDRA Preferred Terms (PTs) for a given input query, ranking them by a relevance score using multi-criteria statistical methods. The system (SafeTerm) embeds medical query terms and MedDRA PTs in a multidimensional vector space, then applies cosine",
      "summary_fr": "In pre-market drug safety review, grouping related adverse event terms into standardised MedDRA queries or the FDA Office of New Drugs Custom Medical Queries (OCMQs) is critical for signal detection. We present a novel quantitative artificial intelligence system that understands and processes medical terminology and automatically retrieves relevant MedDRA Preferred Terms (PTs) for a given input query, ranking them by a relevance score using multi-criteria statistical methods. The system (SafeTerm) embeds medical query terms and MedDRA PTs in a multidimensional vector space, then applies cosine",
      "resume_fr": "In pre-market drug safety review, grouping related adverse event terms into standardised MedDRA queries or the FDA Office of New Drugs Custom Medical Queries (OCMQs) is critical for signal detection. We present a novel quantitative artificial intelligence system that understands and processes medical terminology and automatically retrieves relevant MedDRA Preferred Terms (PTs) for a given input query, ranking them by a relevance score using multi-criteria statistical methods. The system (SafeTerm) embeds medical query terms and MedDRA PTs in a multidimensional vector space, then applies cosine",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 15,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=15, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Dual-Stream Cross-Modal Representation Learning via Residual Semantic Decorrelation",
      "url": "https://arxiv.org/abs/2512.07568v1",
      "source": "arXiv – cs.AI + education/MOOC",
      "published": "2025-12-08T14:01:16.000Z",
      "score": 50,
      "summary_en": "Cross-modal learning has become a fundamental paradigm for integrating heterogeneous information sources such as images, text, and structured attributes. However, multimodal representations often suffer from modality dominance, redundant information coupling, and spurious cross-modal correlations, leading to suboptimal generalization and limited interpretability. In particular, high-variance modalities tend to overshadow weaker but semantically important signals, while naïve fusion strategies entangle modality-shared and modality-specific factors in an uncontrolled manner. This makes it diffic",
      "summary_fr": "Cross-modal learning has become a fundamental paradigm for integrating heterogeneous information sources such as images, text, and structured attributes. However, multimodal representations often suffer from modality dominance, redundant information coupling, and spurious cross-modal correlations, leading to suboptimal generalization and limited interpretability. In particular, high-variance modalities tend to overshadow weaker but semantically important signals, while naïve fusion strategies entangle modality-shared and modality-specific factors in an uncontrolled manner. This makes it diffic",
      "resume_fr": "Cross-modal learning has become a fundamental paradigm for integrating heterogeneous information sources such as images, text, and structured attributes. However, multimodal representations often suffer from modality dominance, redundant information coupling, and spurious cross-modal correlations, leading to suboptimal generalization and limited interpretability. In particular, high-variance modalities tend to overshadow weaker but semantically important signals, while naïve fusion strategies entangle modality-shared and modality-specific factors in an uncontrolled manner. This makes it diffic",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "A Theoretical Framework of Student Agency in AI- Assisted Learning: A Grounded Theory Approach",
      "url": "https://arxiv.org/abs/2512.07143v1",
      "source": "arXiv – cs.HC + education",
      "published": "2025-12-08T03:51:24.000Z",
      "score": 85,
      "summary_en": "Generative AI(GenAI) is a kind of AI model capable of producing human-like content in various modalities, including text, image, audio, video, and computer programming. Although GenAI offers great potential for education, its value often depends on students' ability to engage with it actively, responsibly, and critically - qualities central to student agency. Nevertheless, student agency has long been a complex and ambiguous concept in educational discourses, with few empirical studies clarifying its distinct nature and process in AI-assisted learning environments. To address this gap, the qua",
      "summary_fr": "Generative AI(GenAI) is a kind of AI model capable of producing human-like content in various modalities, including text, image, audio, video, and computer programming. Although GenAI offers great potential for education, its value often depends on students' ability to engage with it actively, responsibly, and critically - qualities central to student agency. Nevertheless, student agency has long been a complex and ambiguous concept in educational discourses, with few empirical studies clarifying its distinct nature and process in AI-assisted learning environments. To address this gap, the qua",
      "resume_fr": "Generative AI(GenAI) is a kind of AI model capable of producing human-like content in various modalities, including text, image, audio, video, and computer programming. Although GenAI offers great potential for education, its value often depends on students' ability to engage with it actively, responsibly, and critically - qualities central to student agency. Nevertheless, student agency has long been a complex and ambiguous concept in educational discourses, with few empirical studies clarifying its distinct nature and process in AI-assisted learning environments. To address this gap, the qua",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Human Agency and Creativity in AI-Assisted Learning Environments",
      "url": "https://arxiv.org/abs/2512.07117v1",
      "source": "arXiv – cs.HC + education",
      "published": "2025-12-08T02:58:23.000Z",
      "score": 50,
      "summary_en": "This chapter explores human creativity in AI-assisted learning environments through the lens of student agency. We begin by examining four theoretical perspectives on agency, including instrumental, effortful, dynamically emergent, and authorial agency, and analyze how each frames the relationship between agency and creativity. Under each theoretical perspective, we discuss how the integration of generative AI (GenAI) tools reshapes these dynamics by altering students' roles in cognitive, social, and creative processes. In the second part, we introduce a theoretical framework for AI agentic en",
      "summary_fr": "This chapter explores human creativity in AI-assisted learning environments through the lens of student agency. We begin by examining four theoretical perspectives on agency, including instrumental, effortful, dynamically emergent, and authorial agency, and analyze how each frames the relationship between agency and creativity. Under each theoretical perspective, we discuss how the integration of generative AI (GenAI) tools reshapes these dynamics by altering students' roles in cognitive, social, and creative processes. In the second part, we introduce a theoretical framework for AI agentic en",
      "resume_fr": "This chapter explores human creativity in AI-assisted learning environments through the lens of student agency. We begin by examining four theoretical perspectives on agency, including instrumental, effortful, dynamically emergent, and authorial agency, and analyze how each frames the relationship between agency and creativity. Under each theoretical perspective, we discuss how the integration of generative AI (GenAI) tools reshapes these dynamics by altering students' roles in cognitive, social, and creative processes. In the second part, we introduce a theoretical framework for AI agentic en",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Singing Timbre Popularity Assessment Based on Multimodal Large Foundation Model",
      "url": "https://arxiv.org/abs/2512.06999v1",
      "source": "arXiv – cs.AI + education/MOOC",
      "published": "2025-12-07T21:06:16.000Z",
      "score": 50,
      "summary_en": "Automated singing assessment is crucial for education and entertainment. However, existing systems face two fundamental limitations: reliance on reference tracks, which stifles creative expression, and the simplification of complex performances into non-diagnostic scores based solely on pitch and rhythm. We advocate for a shift from discriminative to descriptive evaluation, creating a complete ecosystem for reference-free, multi-dimensional assessment. First, we introduce Sing-MD, a large-scale dataset annotated by experts across four dimensions: breath control, timbre quality, emotional expre",
      "summary_fr": "Automated singing assessment is crucial for education and entertainment. However, existing systems face two fundamental limitations: reliance on reference tracks, which stifles creative expression, and the simplification of complex performances into non-diagnostic scores based solely on pitch and rhythm. We advocate for a shift from discriminative to descriptive evaluation, creating a complete ecosystem for reference-free, multi-dimensional assessment. First, we introduce Sing-MD, a large-scale dataset annotated by experts across four dimensions: breath control, timbre quality, emotional expre",
      "resume_fr": "Automated singing assessment is crucial for education and entertainment. However, existing systems face two fundamental limitations: reliance on reference tracks, which stifles creative expression, and the simplification of complex performances into non-diagnostic scores based solely on pitch and rhythm. We advocate for a shift from discriminative to descriptive evaluation, creating a complete ecosystem for reference-free, multi-dimensional assessment. First, we introduce Sing-MD, a large-scale dataset annotated by experts across four dimensions: breath control, timbre quality, emotional expre",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "NeuroABench: A Multimodal Evaluation Benchmark for Neurosurgical Anatomy Identification",
      "url": "https://arxiv.org/abs/2512.06921v1",
      "source": "arXiv – cs.AI + education/MOOC",
      "published": "2025-12-07T17:00:25.000Z",
      "score": 50,
      "summary_en": "Multimodal Large Language Models (MLLMs) have shown significant potential in surgical video understanding. With improved zero-shot performance and more effective human-machine interaction, they provide a strong foundation for advancing surgical education and assistance. However, existing research and datasets primarily focus on understanding surgical procedures and workflows, while paying limited attention to the critical role of anatomical comprehension. In clinical practice, surgeons rely heavily on precise anatomical understanding to interpret, review, and learn from surgical videos. To fil",
      "summary_fr": "Multimodal Large Language Models (MLLMs) have shown significant potential in surgical video understanding. With improved zero-shot performance and more effective human-machine interaction, they provide a strong foundation for advancing surgical education and assistance. However, existing research and datasets primarily focus on understanding surgical procedures and workflows, while paying limited attention to the critical role of anatomical comprehension. In clinical practice, surgeons rely heavily on precise anatomical understanding to interpret, review, and learn from surgical videos. To fil",
      "resume_fr": "Multimodal Large Language Models (MLLMs) have shown significant potential in surgical video understanding. With improved zero-shot performance and more effective human-machine interaction, they provide a strong foundation for advancing surgical education and assistance. However, existing research and datasets primarily focus on understanding surgical procedures and workflows, while paying limited attention to the critical role of anatomical comprehension. In clinical practice, surgeons rely heavily on precise anatomical understanding to interpret, review, and learn from surgical videos. To fil",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Exploring Teenagers' Trust in Al Chatbots: An Empirical Study of Chinese Middle-School Students",
      "url": "https://arxiv.org/abs/2512.06647v1",
      "source": "arXiv – cs.HC + education",
      "published": "2025-12-07T04:13:27.000Z",
      "score": 50,
      "summary_en": "Chatbots have become increasingly prevalent. A growing body of research focused on the issue of human trust in AI. However, most existing user studies are conducted primarily with adult groups, overlooking teenagers who are also engaging more frequently with AI technologies. Based on previous theories about teenage education and psychology, this study investigates the correlation between teenagers' psychological characteristics and their trust in AI chatbots, examining four key variables: AI literacy, ego identity, social anxiety, and psychological resilience. We adopted a mixed-methods approa",
      "summary_fr": "Chatbots have become increasingly prevalent. A growing body of research focused on the issue of human trust in AI. However, most existing user studies are conducted primarily with adult groups, overlooking teenagers who are also engaging more frequently with AI technologies. Based on previous theories about teenage education and psychology, this study investigates the correlation between teenagers' psychological characteristics and their trust in AI chatbots, examining four key variables: AI literacy, ego identity, social anxiety, and psychological resilience. We adopted a mixed-methods approa",
      "resume_fr": "Chatbots have become increasingly prevalent. A growing body of research focused on the issue of human trust in AI. However, most existing user studies are conducted primarily with adult groups, overlooking teenagers who are also engaging more frequently with AI technologies. Based on previous theories about teenage education and psychology, this study investigates the correlation between teenagers' psychological characteristics and their trust in AI chatbots, examining four key variables: AI literacy, ego identity, social anxiety, and psychological resilience. We adopted a mixed-methods approa",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Classifying German Language Proficiency Levels Using Large Language Models",
      "url": "https://arxiv.org/abs/2512.06483v1",
      "source": "arXiv – cs.AI + education/MOOC",
      "published": "2025-12-06T16:15:45.000Z",
      "score": 50,
      "summary_en": "Assessing language proficiency is essential for education, as it enables instruction tailored to learners needs. This paper investigates the use of Large Language Models (LLMs) for automatically classifying German texts according to the Common European Framework of Reference for Languages (CEFR) into different proficiency levels. To support robust training and evaluation, we construct a diverse dataset by combining multiple existing CEFR-annotated corpora with synthetic data. We then evaluate prompt-engineering strategies, fine-tuning of a LLaMA-3-8B-Instruct model and a probing-based approach",
      "summary_fr": "Assessing language proficiency is essential for education, as it enables instruction tailored to learners needs. This paper investigates the use of Large Language Models (LLMs) for automatically classifying German texts according to the Common European Framework of Reference for Languages (CEFR) into different proficiency levels. To support robust training and evaluation, we construct a diverse dataset by combining multiple existing CEFR-annotated corpora with synthetic data. We then evaluate prompt-engineering strategies, fine-tuning of a LLaMA-3-8B-Instruct model and a probing-based approach",
      "resume_fr": "Assessing language proficiency is essential for education, as it enables instruction tailored to learners needs. This paper investigates the use of Large Language Models (LLMs) for automatically classifying German texts according to the Common European Framework of Reference for Languages (CEFR) into different proficiency levels. To support robust training and evaluation, we construct a diverse dataset by combining multiple existing CEFR-annotated corpora with synthetic data. We then evaluate prompt-engineering strategies, fine-tuning of a LLaMA-3-8B-Instruct model and a probing-based approach",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Entrepreneurship Program Brings Incubator Ideas to More Countries",
      "url": "https://spectrum.ieee.org/ieee-entrepreneurship-program-more-countries",
      "source": "IEEE Spectrum – AI",
      "published": "2025-12-05T19:00:02.000Z",
      "score": 50,
      "summary_en": "Technology evolves rapidly, and innovation is key to business survival, so mentoring young professionals, promoting entrepreneurship, and connecting tech startups to a global network of experts and resources are essential. Some IEEE volunteers do all of the above and more as part of the IEEE Entrepreneurship Ambassador Program. The program was launched in 2018 in IEEE Region 8 (Europe, Middle East, and Africa) thanks to a grant from the IEEE Foundation. The ambassadors organize networking events with industry representatives to help IEEE young professionals and student members achieve their en",
      "summary_fr": "Technology evolves rapidly, and innovation is key to business survival, so mentoring young professionals, promoting entrepreneurship, and connecting tech startups to a global network of experts and resources are essential. Some IEEE volunteers do all of the above and more as part of the IEEE Entrepreneurship Ambassador Program. The program was launched in 2018 in IEEE Region 8 (Europe, Middle East, and Africa) thanks to a grant from the IEEE Foundation. The ambassadors organize networking events with industry representatives to help IEEE young professionals and student members achieve their en",
      "resume_fr": "Technology evolves rapidly, and innovation is key to business survival, so mentoring young professionals, promoting entrepreneurship, and connecting tech startups to a global network of experts and resources are essential. Some IEEE volunteers do all of the above and more as part of the IEEE Entrepreneurship Ambassador Program. The program was launched in 2018 in IEEE Region 8 (Europe, Middle East, and Africa) thanks to a grant from the IEEE Foundation. The ambassadors organize networking events with industry representatives to help IEEE young professionals and student members achieve their en",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 15,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=15, Impact=0.",
      "image": "https://spectrum.ieee.org/media-library/susan-lau-natasha-main-ryan-ramkhelawan-and-julia-proto-posing-in-front-of-several-international-flags.jpg?id=62282024&width=1200&height=600&coordinates=0%2C250%2C0%2C250"
    },
    {
      "title": "Enhancing Retrieval-Augmented Generation with Entity Linking for Educational Platforms",
      "url": "https://arxiv.org/abs/2512.05967v1",
      "source": "arXiv – cs.AI + education/MOOC",
      "published": "2025-12-05T18:59:18.000Z",
      "score": 50,
      "summary_en": "In the era of Large Language Models (LLMs), Retrieval-Augmented Generation (RAG) architectures are gaining significant attention for their ability to ground language generation in reliable knowledge sources. Despite their impressive effectiveness in many areas, RAG systems based solely on semantic similarity often fail to ensure factual accuracy in specialized domains, where terminological ambiguity can affect retrieval relevance. This study proposes an enhanced RAG architecture that integrates a factual signal derived from Entity Linking to improve the accuracy of educational question-answeri",
      "summary_fr": "In the era of Large Language Models (LLMs), Retrieval-Augmented Generation (RAG) architectures are gaining significant attention for their ability to ground language generation in reliable knowledge sources. Despite their impressive effectiveness in many areas, RAG systems based solely on semantic similarity often fail to ensure factual accuracy in specialized domains, where terminological ambiguity can affect retrieval relevance. This study proposes an enhanced RAG architecture that integrates a factual signal derived from Entity Linking to improve the accuracy of educational question-answeri",
      "resume_fr": "In the era of Large Language Models (LLMs), Retrieval-Augmented Generation (RAG) architectures are gaining significant attention for their ability to ground language generation in reliable knowledge sources. Despite their impressive effectiveness in many areas, RAG systems based solely on semantic similarity often fail to ensure factual accuracy in specialized domains, where terminological ambiguity can affect retrieval relevance. This study proposes an enhanced RAG architecture that integrates a factual signal derived from Entity Linking to improve the accuracy of educational question-answeri",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Optimizing Medical Question-Answering Systems: A Comparative Study of Fine-Tuned and Zero-Shot Large Language Models with RAG Framework",
      "url": "https://arxiv.org/abs/2512.05863v1",
      "source": "arXiv – cs.CL (NLP/LLM)",
      "published": "2025-12-05T16:38:47.000Z",
      "score": 70,
      "summary_en": "Medical question-answering (QA) systems can benefit from advances in large language models (LLMs), but directly applying LLMs to the clinical domain poses challenges such as maintaining factual accuracy and avoiding hallucinations. In this paper, we present a retrieval-augmented generation (RAG) based medical QA system that combines domain-specific knowledge retrieval with open-source LLMs to answer medical questions. We fine-tune two state-of-the-art open LLMs (LLaMA~2 and Falcon) using Low-Rank Adaptation (LoRA) for efficient domain specialization. The system retrieves relevant medical liter",
      "summary_fr": "Medical question-answering (QA) systems can benefit from advances in large language models (LLMs), but directly applying LLMs to the clinical domain poses challenges such as maintaining factual accuracy and avoiding hallucinations. In this paper, we present a retrieval-augmented generation (RAG) based medical QA system that combines domain-specific knowledge retrieval with open-source LLMs to answer medical questions. We fine-tune two state-of-the-art open LLMs (LLaMA~2 and Falcon) using Low-Rank Adaptation (LoRA) for efficient domain specialization. The system retrieves relevant medical liter",
      "resume_fr": "Medical question-answering (QA) systems can benefit from advances in large language models (LLMs), but directly applying LLMs to the clinical domain poses challenges such as maintaining factual accuracy and avoiding hallucinations. In this paper, we present a retrieval-augmented generation (RAG) based medical QA system that combines domain-specific knowledge retrieval with open-source LLMs to answer medical questions. We fine-tune two state-of-the-art open LLMs (LLaMA~2 and Falcon) using Low-Rank Adaptation (LoRA) for efficient domain specialization. The system retrieves relevant medical liter",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Prompting Science Report 4: Playing Pretend: Expert Personas Don't Improve Factual Accuracy",
      "url": "https://arxiv.org/abs/2512.05858v1",
      "source": "arXiv – cs.CL (NLP/LLM)",
      "published": "2025-12-05T16:35:18.000Z",
      "score": 70,
      "summary_en": "This is the fourth in a series of short reports that help business, education, and policy leaders understand the technical details of working with AI through rigorous testing. Here, we ask whether assigning personas to models improves performance on difficult objective multiple-choice questions. We study both domain-specific expert personas and low-knowledge personas, evaluating six models on GPQA Diamond (Rein et al. 2024) and MMLU-Pro (Wang et al. 2024), graduate-level questions spanning science, engineering, and law. We tested three approaches: -In-Domain Experts: Assigning the model an exp",
      "summary_fr": "This is the fourth in a series of short reports that help business, education, and policy leaders understand the technical details of working with AI through rigorous testing. Here, we ask whether assigning personas to models improves performance on difficult objective multiple-choice questions. We study both domain-specific expert personas and low-knowledge personas, evaluating six models on GPQA Diamond (Rein et al. 2024) and MMLU-Pro (Wang et al. 2024), graduate-level questions spanning science, engineering, and law. We tested three approaches: -In-Domain Experts: Assigning the model an exp",
      "resume_fr": "This is the fourth in a series of short reports that help business, education, and policy leaders understand the technical details of working with AI through rigorous testing. Here, we ask whether assigning personas to models improves performance on difficult objective multiple-choice questions. We study both domain-specific expert personas and low-knowledge personas, evaluating six models on GPQA Diamond (Rein et al. 2024) and MMLU-Pro (Wang et al. 2024), graduate-level questions spanning science, engineering, and law. We tested three approaches: -In-Domain Experts: Assigning the model an exp",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "When Scaffolding Breaks: Investigating Student Interaction with LLM-Based Writing Support in Real-Time K-12 EFL Classrooms",
      "url": "https://arxiv.org/abs/2512.05506v1",
      "source": "arXiv – cs.HC + education",
      "published": "2025-12-05T08:09:05.000Z",
      "score": 85,
      "summary_en": "Large language models (LLMs) are promising tools for scaffolding students' English writing skills, but their effectiveness in real-time K-12 classrooms remains underexplored. Addressing this gap, our study examines the benefits and limitations of using LLMs as real-time learning support, considering how classroom constraints, such as diverse proficiency levels and limited time, affect their effectiveness. We conducted a deployment study with 157 eighth-grade students in a South Korean middle school English class over six weeks. Our findings reveal that while scaffolding improved students' abil",
      "summary_fr": "Large language models (LLMs) are promising tools for scaffolding students' English writing skills, but their effectiveness in real-time K-12 classrooms remains underexplored. Addressing this gap, our study examines the benefits and limitations of using LLMs as real-time learning support, considering how classroom constraints, such as diverse proficiency levels and limited time, affect their effectiveness. We conducted a deployment study with 157 eighth-grade students in a South Korean middle school English class over six weeks. Our findings reveal that while scaffolding improved students' abil",
      "resume_fr": "Large language models (LLMs) are promising tools for scaffolding students' English writing skills, but their effectiveness in real-time K-12 classrooms remains underexplored. Addressing this gap, our study examines the benefits and limitations of using LLMs as real-time learning support, considering how classroom constraints, such as diverse proficiency levels and limited time, affect their effectiveness. We conducted a deployment study with 157 eighth-grade students in a South Korean middle school English class over six weeks. Our findings reveal that while scaffolding improved students' abil",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Building Capacity for Artificial Intelligence in Africa: A Cross-Country Survey of Challenges and Governance Pathways",
      "url": "https://arxiv.org/abs/2512.05432v1",
      "source": "arXiv – cs.AI + education/MOOC",
      "published": "2025-12-05T05:14:23.000Z",
      "score": 50,
      "summary_en": "Artificial intelligence (AI) is transforming education and the workforce, but access to AI learning opportunities in Africa remains uneven. With rapid demographic shifts and growing labour market pressures, AI has become a strategic development priority, making the demand for relevant skills more urgent. This study investigates how universities and industries engage in shaping AI education and workforce preparation, drawing on survey responses from five African countries (Ghana, Namibia, Rwanda, Kenya and Zambia). The findings show broad recognition of AI importance but limited evidence of con",
      "summary_fr": "Artificial intelligence (AI) is transforming education and the workforce, but access to AI learning opportunities in Africa remains uneven. With rapid demographic shifts and growing labour market pressures, AI has become a strategic development priority, making the demand for relevant skills more urgent. This study investigates how universities and industries engage in shaping AI education and workforce preparation, drawing on survey responses from five African countries (Ghana, Namibia, Rwanda, Kenya and Zambia). The findings show broad recognition of AI importance but limited evidence of con",
      "resume_fr": "Artificial intelligence (AI) is transforming education and the workforce, but access to AI learning opportunities in Africa remains uneven. With rapid demographic shifts and growing labour market pressures, AI has become a strategic development priority, making the demand for relevant skills more urgent. This study investigates how universities and industries engage in shaping AI education and workforce preparation, drawing on survey responses from five African countries (Ghana, Namibia, Rwanda, Kenya and Zambia). The findings show broad recognition of AI importance but limited evidence of con",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Learning to Code with Context: A Study-Based Approach",
      "url": "https://arxiv.org/abs/2512.05242v1",
      "source": "arXiv – cs.AI + education/MOOC",
      "published": "2025-12-04T20:40:36.000Z",
      "score": 50,
      "summary_en": "The rapid emergence of generative AI tools is transforming the way software is developed. Consequently, software engineering education must adapt to ensure that students not only learn traditional development methods but also understand how to meaningfully and responsibly use these new technologies. In particular, project-based courses offer an effective environment to explore and evaluate the integration of AI assistance into real-world development practices. This paper presents our approach and a user study conducted within a university programming project in which students collaboratively d",
      "summary_fr": "The rapid emergence of generative AI tools is transforming the way software is developed. Consequently, software engineering education must adapt to ensure that students not only learn traditional development methods but also understand how to meaningfully and responsibly use these new technologies. In particular, project-based courses offer an effective environment to explore and evaluate the integration of AI assistance into real-world development practices. This paper presents our approach and a user study conducted within a university programming project in which students collaboratively d",
      "resume_fr": "The rapid emergence of generative AI tools is transforming the way software is developed. Consequently, software engineering education must adapt to ensure that students not only learn traditional development methods but also understand how to meaningfully and responsibly use these new technologies. In particular, project-based courses offer an effective environment to explore and evaluate the integration of AI assistance into real-world development practices. This paper presents our approach and a user study conducted within a university programming project in which students collaboratively d",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Value Gradient Guidance for Flow Matching Alignment",
      "url": "https://arxiv.org/abs/2512.05116v1",
      "source": "arXiv – cs.LG + learning analytics",
      "published": "2025-12-04T18:59:57.000Z",
      "score": 70,
      "summary_en": "While methods exist for aligning flow matching models--a popular and effective class of generative models--with human preferences, existing approaches fail to achieve both adaptation efficiency and probabilistically sound prior preservation. In this work, we leverage the theory of optimal control and propose VGG-Flow, a gradient-matching-based method for finetuning pretrained flow matching models. The key idea behind this algorithm is that the optimal difference between the finetuned velocity field and the pretrained one should be matched with the gradient field of a value function. This metho",
      "summary_fr": "While methods exist for aligning flow matching models--a popular and effective class of generative models--with human preferences, existing approaches fail to achieve both adaptation efficiency and probabilistically sound prior preservation. In this work, we leverage the theory of optimal control and propose VGG-Flow, a gradient-matching-based method for finetuning pretrained flow matching models. The key idea behind this algorithm is that the optimal difference between the finetuned velocity field and the pretrained one should be matched with the gradient field of a value function. This metho",
      "resume_fr": "While methods exist for aligning flow matching models--a popular and effective class of generative models--with human preferences, existing approaches fail to achieve both adaptation efficiency and probabilistically sound prior preservation. In this work, we leverage the theory of optimal control and propose VGG-Flow, a gradient-matching-based method for finetuning pretrained flow matching models. The key idea behind this algorithm is that the optimal difference between the finetuned velocity field and the pretrained one should be matched with the gradient field of a value function. This metho",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "TV2TV: A Unified Framework for Interleaved Language and Video Generation",
      "url": "https://arxiv.org/abs/2512.05103v1",
      "source": "arXiv – cs.LG + learning analytics",
      "published": "2025-12-04T18:59:09.000Z",
      "score": 70,
      "summary_en": "Video generation models are rapidly advancing, but can still struggle with complex video outputs that require significant semantic branching or repeated high-level reasoning about what should happen next. In this paper, we introduce a new class of omni video-text models that integrate ideas from recent LM reasoning advances to address this challenge. More specifically, we present TV2TV, a unified generative modeling framework which decomposes video generation into an interleaved text and video generation process. TV2TV jointly learns language modeling (next-token prediction) and video flow mat",
      "summary_fr": "Video generation models are rapidly advancing, but can still struggle with complex video outputs that require significant semantic branching or repeated high-level reasoning about what should happen next. In this paper, we introduce a new class of omni video-text models that integrate ideas from recent LM reasoning advances to address this challenge. More specifically, we present TV2TV, a unified generative modeling framework which decomposes video generation into an interleaved text and video generation process. TV2TV jointly learns language modeling (next-token prediction) and video flow mat",
      "resume_fr": "Video generation models are rapidly advancing, but can still struggle with complex video outputs that require significant semantic branching or repeated high-level reasoning about what should happen next. In this paper, we introduce a new class of omni video-text models that integrate ideas from recent LM reasoning advances to address this challenge. More specifically, we present TV2TV, a unified generative modeling framework which decomposes video generation into an interleaved text and video generation process. TV2TV jointly learns language modeling (next-token prediction) and video flow mat",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Fine-Tuning BERT for Domain-Specific Question Answering: Toward Educational NLP Resources at University Scale",
      "url": "https://arxiv.org/abs/2512.05179v1",
      "source": "arXiv – cs.AI + education/MOOC",
      "published": "2025-12-04T18:27:46.000Z",
      "score": 50,
      "summary_en": "Prior work on scientific question answering has largely emphasized chatbot-style systems, with limited exploration of fine-tuning foundation models for domain-specific reasoning. In this study, we developed a chatbot for the University of Limerick's Department of Electronic and Computer Engineering to provide course information to students. A custom dataset of 1,203 question-answer pairs in SQuAD format was constructed using the university book of modules, supplemented with manually and synthetically generated entries. We fine-tuned BERT (Devlin et al., 2019) using PyTorch and evaluated perfor",
      "summary_fr": "Prior work on scientific question answering has largely emphasized chatbot-style systems, with limited exploration of fine-tuning foundation models for domain-specific reasoning. In this study, we developed a chatbot for the University of Limerick's Department of Electronic and Computer Engineering to provide course information to students. A custom dataset of 1,203 question-answer pairs in SQuAD format was constructed using the university book of modules, supplemented with manually and synthetically generated entries. We fine-tuned BERT (Devlin et al., 2019) using PyTorch and evaluated perfor",
      "resume_fr": "Prior work on scientific question answering has largely emphasized chatbot-style systems, with limited exploration of fine-tuning foundation models for domain-specific reasoning. In this study, we developed a chatbot for the University of Limerick's Department of Electronic and Computer Engineering to provide course information to students. A custom dataset of 1,203 question-answer pairs in SQuAD format was constructed using the university book of modules, supplemented with manually and synthetically generated entries. We fine-tuned BERT (Devlin et al., 2019) using PyTorch and evaluated perfor",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Model-Free Assessment of Simulator Fidelity via Quantile Curves",
      "url": "https://arxiv.org/abs/2512.05024v1",
      "source": "arXiv – cs.AI + education/MOOC",
      "published": "2025-12-04T17:39:51.000Z",
      "score": 50,
      "summary_en": "Simulation of complex systems originated in manufacturing and queuing applications. It is now widely used for large-scale, ML-based systems in research, education, and consumer surveys. However, characterizing the discrepancy between simulators and ground truth remains challenging for increasingly complex, machine-learning-based systems. We propose a computationally tractable method to estimate the quantile function of the discrepancy between the simulated and ground-truth outcome distributions. Our approach focuses on output uncertainty and treats the simulator as a black box, imposing no mod",
      "summary_fr": "Simulation of complex systems originated in manufacturing and queuing applications. It is now widely used for large-scale, ML-based systems in research, education, and consumer surveys. However, characterizing the discrepancy between simulators and ground truth remains challenging for increasingly complex, machine-learning-based systems. We propose a computationally tractable method to estimate the quantile function of the discrepancy between the simulated and ground-truth outcome distributions. Our approach focuses on output uncertainty and treats the simulator as a black box, imposing no mod",
      "resume_fr": "Simulation of complex systems originated in manufacturing and queuing applications. It is now widely used for large-scale, ML-based systems in research, education, and consumer surveys. However, characterizing the discrepancy between simulators and ground truth remains challenging for increasingly complex, machine-learning-based systems. We propose a computationally tractable method to estimate the quantile function of the discrepancy between the simulated and ground-truth outcome distributions. Our approach focuses on output uncertainty and treats the simulator as a black box, imposing no mod",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Factuality and Transparency Are All RAG Needs! Self-Explaining Contrastive Evidence Re-ranking",
      "url": "https://arxiv.org/abs/2512.05012v1",
      "source": "arXiv – cs.CL (NLP/LLM)",
      "published": "2025-12-04T17:24:35.000Z",
      "score": 70,
      "summary_en": "This extended abstract introduces Self-Explaining Contrastive Evidence Re-Ranking (CER), a novel method that restructures retrieval around factual evidence by fine-tuning embeddings with contrastive learning and generating token-level attribution rationales for each retrieved passage. Hard negatives are automatically selected using a subjectivity-based criterion, forcing the model to pull factual rationales closer while pushing subjective or misleading explanations apart. As a result, the method creates an embedding space explicitly aligned with evidential reasoning. We evaluated our method on",
      "summary_fr": "This extended abstract introduces Self-Explaining Contrastive Evidence Re-Ranking (CER), a novel method that restructures retrieval around factual evidence by fine-tuning embeddings with contrastive learning and generating token-level attribution rationales for each retrieved passage. Hard negatives are automatically selected using a subjectivity-based criterion, forcing the model to pull factual rationales closer while pushing subjective or misleading explanations apart. As a result, the method creates an embedding space explicitly aligned with evidential reasoning. We evaluated our method on",
      "resume_fr": "This extended abstract introduces Self-Explaining Contrastive Evidence Re-Ranking (CER), a novel method that restructures retrieval around factual evidence by fine-tuning embeddings with contrastive learning and generating token-level attribution rationales for each retrieved passage. Hard negatives are automatically selected using a subjectivity-based criterion, forcing the model to pull factual rationales closer while pushing subjective or misleading explanations apart. As a result, the method creates an embedding space explicitly aligned with evidential reasoning. We evaluated our method on",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Declarative Synthesis and Multi-Objective Optimization of Stripboard Circuit Layouts Using Answer Set Programming",
      "url": "https://arxiv.org/abs/2512.04910v1",
      "source": "arXiv – cs.AI + education/MOOC",
      "published": "2025-12-04T15:37:59.000Z",
      "score": 50,
      "summary_en": "This paper presents a novel approach to automated stripboard circuit layout design using Answer Set Programming (ASP). The work formulates the layout problem as both a synthesis and multi-objective optimization task that simultaneously generates viable layouts while minimizing board area and component strip crossing. By leveraging ASP's declarative nature, this work expresses complex geometric and electrical constraints in a natural and concise manner. The two-phase solving methodology first ensures feasibility before optimizing layout quality. Experimental results demonstrate that this approa",
      "summary_fr": "This paper presents a novel approach to automated stripboard circuit layout design using Answer Set Programming (ASP). The work formulates the layout problem as both a synthesis and multi-objective optimization task that simultaneously generates viable layouts while minimizing board area and component strip crossing. By leveraging ASP's declarative nature, this work expresses complex geometric and electrical constraints in a natural and concise manner. The two-phase solving methodology first ensures feasibility before optimizing layout quality. Experimental results demonstrate that this approa",
      "resume_fr": "This paper presents a novel approach to automated stripboard circuit layout design using Answer Set Programming (ASP). The work formulates the layout problem as both a synthesis and multi-objective optimization task that simultaneously generates viable layouts while minimizing board area and component strip crossing. By leveraging ASP's declarative nature, this work expresses complex geometric and electrical constraints in a natural and concise manner. The two-phase solving methodology first ensures feasibility before optimizing layout quality. Experimental results demonstrate that this approa",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Bridging Traditional Machine Learning and Large Language Models: A Two-Part Course Design for Modern AI Education",
      "url": "https://arxiv.org/abs/2512.05167v1",
      "source": "arXiv – cs.AI + education/MOOC",
      "published": "2025-12-04T15:10:37.000Z",
      "score": 50,
      "summary_en": "This paper presents an innovative pedagogical approach for teaching artificial intelligence and data science that systematically bridges traditional machine learning techniques with modern Large Language Models (LLMs). We describe a course structured in two sequential and complementary parts: foundational machine learning concepts and contemporary LLM applications. This design enables students to develop a comprehensive understanding of AI evolution while building practical skills with both established and cutting-edge technologies. We detail the course architecture, implementation strategies,",
      "summary_fr": "This paper presents an innovative pedagogical approach for teaching artificial intelligence and data science that systematically bridges traditional machine learning techniques with modern Large Language Models (LLMs). We describe a course structured in two sequential and complementary parts: foundational machine learning concepts and contemporary LLM applications. This design enables students to develop a comprehensive understanding of AI evolution while building practical skills with both established and cutting-edge technologies. We detail the course architecture, implementation strategies,",
      "resume_fr": "This paper presents an innovative pedagogical approach for teaching artificial intelligence and data science that systematically bridges traditional machine learning techniques with modern Large Language Models (LLMs). We describe a course structured in two sequential and complementary parts: foundational machine learning concepts and contemporary LLM applications. This design enables students to develop a comprehensive understanding of AI evolution while building practical skills with both established and cutting-edge technologies. We detail the course architecture, implementation strategies,",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    }
  ]
}