{
  "generatedAt": "2025-11-22T06:34:08.659Z",
  "model": "gpt-5",
  "profile": "balanced",
  "threshold": 65,
  "totalAnalyzed": 100,
  "totalPublished": 36,
  "publishTarget": "default",
  "debug": {
    "analysisFailed": true,
    "usedLLM": false,
    "useOpenAIEnv": true,
    "hasOpenAIKey": true,
    "minPublish": 12,
    "weightsUsed": {
      "research": 35,
      "policy": 35,
      "institution": 15,
      "impact": 15
    },
    "labelsUsed": {
      "research": "Recherche",
      "policy": "Politiques",
      "institution": "Institution",
      "impact": "Impact"
    },
    "descUsed": {
      "research": "articles/journaux, conférences, CFP, résultats scientifiques",
      "policy": "lois, régulations, standards, cadres, gouvernance",
      "institution": "communiqués des grandes agences et autorités (UNESCO, OCDE, CNIL, ministères…)",
      "impact": "impact direct pour la classe/enseignants/universités/EdTech"
    },
    "keysUsed": {
      "research": [
        "arxiv",
        "preprint",
        "doi",
        "journal",
        "conference",
        "proceedings",
        "workshop",
        "submission",
        "cfp",
        "acceptance",
        "springer",
        "wiley",
        "nature",
        "frontiers",
        "acm",
        "ieee"
      ],
      "policy": [
        "ai act",
        "regulation",
        "régulation",
        "policy",
        "politique",
        "standard",
        "framework",
        "guidance",
        "law",
        "act",
        "ordonnance",
        "décret",
        "ethics",
        "ethical"
      ],
      "institution": [
        "unesco",
        "oecd",
        "ocde",
        "cnil",
        "edps",
        "ncsc",
        "minist",
        "commission",
        "nsf",
        "ukri",
        "ies",
        "european commission"
      ],
      "impact": [
        "school",
        "education",
        "teacher",
        "enseignant",
        "k-12",
        "universit",
        "student",
        "pupil",
        "mooc",
        "classroom",
        "edtech"
      ]
    }
  },
  "items": [
    {
      "title": "Balancing Physical Security and Privacy in Higher Education: A Practical Guide",
      "url": "https://edtechmagazine.com/higher/article/2025/11/balancing-physical-security-and-privacy-higher-education-practical-guide",
      "source": "EdTech Magazine (Higher Ed)",
      "published": "2025-11-20T21:56:06.000Z",
      "score": 50,
      "summary_en": "Video surveillance, face recognition and artificial intelligence have become common in physical security. For colleges and universities, that raises some serious questions about privacy. Benefits to the safety and well-being of students range from being able to more quickly identify an on-campus intruder to improving access control for staff and faculty. But the potential risks include new administrative burdens, spiraling costs and running afoul of local privacy laws. The key to using cutting-edge physical security technology responsibly is striking a balance among protecting people,…",
      "summary_fr": "Video surveillance, face recognition and artificial intelligence have become common in physical security. For colleges and universities, that raises some serious questions about privacy. Benefits to the safety and well-being of students range from being able to more quickly identify an on-campus intruder to improving access control for staff and faculty. But the potential risks include new administrative burdens, spiraling costs and running afoul of local privacy laws. The key to using cutting-edge physical security technology responsibly is striking a balance among protecting people,…",
      "resume_fr": "Video surveillance, face recognition and artificial intelligence have become common in physical security. For colleges and universities, that raises some serious questions about privacy. Benefits to the safety and well-being of students range from being able to more quickly identify an on-campus intruder to improving access control for staff and faculty. But the potential risks include new administrative burdens, spiraling costs and running afoul of local privacy laws. The key to using cutting-edge physical security technology responsibly is striking a balance among protecting people,…",
      "tags": [],
      "breakdown": {
        "research": 0,
        "policy": 35,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=0, Politiques=35, Institution=0, Impact=15.",
      "image": "https://edtechmagazine.com/higher/sites/edtechmagazine.com.higher/files/styles/cdw_hero/public/articles/%5Bcdw_tech_site%3Afield_site_shortname%5D/202511/GettyImages-2198968310.jpg?itok=KJV60sbW"
    },
    {
      "title": "Develop a deeper understanding with interactive images in Gemini.",
      "url": "https://blog.google/outreach-initiatives/education/gemini-interactive-images/",
      "source": "Google for Education – Blog",
      "published": "2025-11-20T20:30:00.000Z",
      "score": 50,
      "summary_en": "Learning science consistently shows us that true learning requires active engagement. This is fundamental to how Gemini helps you learn. Going beyond simple text and sta…",
      "summary_fr": "Learning science consistently shows us that true learning requires active engagement. This is fundamental to how Gemini helps you learn. Going beyond simple text and sta…",
      "resume_fr": "Learning science consistently shows us that true learning requires active engagement. This is fundamental to how Gemini helps you learn. Going beyond simple text and sta…",
      "tags": [],
      "breakdown": {
        "research": 0,
        "policy": 35,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=0, Politiques=35, Institution=0, Impact=15.",
      "image": "https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/wagtailvideo-e6k80n42_thumb.jpg"
    },
    {
      "title": "Evolution Strategies at the Hyperscale",
      "url": "https://arxiv.org/abs/2511.16652v1",
      "source": "arXiv – cs.LG + learning analytics",
      "published": "2025-11-20T18:56:05.000Z",
      "score": 50,
      "summary_en": "We introduce Evolution Guided General Optimization via Low-rank Learning (EGGROLL), an evolution strategies (ES) algorithm designed to scale backprop-free optimization to large population sizes for modern large neural network architectures with billions of parameters. ES is a set of powerful blackbox optimisation methods that can handle non-differentiable or noisy objectives with excellent scaling potential through parallelisation. Na{ï}ve ES becomes prohibitively expensive at scale due to the computational and memory costs associated with generating matrix perturbations $E\\in\\mathbb{R}^{m\\tim",
      "summary_fr": "We introduce Evolution Guided General Optimization via Low-rank Learning (EGGROLL), an evolution strategies (ES) algorithm designed to scale backprop-free optimization to large population sizes for modern large neural network architectures with billions of parameters. ES is a set of powerful blackbox optimisation methods that can handle non-differentiable or noisy objectives with excellent scaling potential through parallelisation. Na{ï}ve ES becomes prohibitively expensive at scale due to the computational and memory costs associated with generating matrix perturbations $E\\in\\mathbb{R}^{m\\tim",
      "resume_fr": "We introduce Evolution Guided General Optimization via Low-rank Learning (EGGROLL), an evolution strategies (ES) algorithm designed to scale backprop-free optimization to large population sizes for modern large neural network architectures with billions of parameters. ES is a set of powerful blackbox optimisation methods that can handle non-differentiable or noisy objectives with excellent scaling potential through parallelisation. Na{ï}ve ES becomes prohibitively expensive at scale due to the computational and memory costs associated with generating matrix perturbations $E\\in\\mathbb{R}^{m\\tim",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 15,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=15, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Stabilizing Policy Gradient Methods via Reward Profiling",
      "url": "https://arxiv.org/abs/2511.16629v1",
      "source": "arXiv – cs.LG + learning analytics",
      "published": "2025-11-20T18:35:51.000Z",
      "score": 70,
      "summary_en": "Policy gradient methods, which have been extensively studied in the last decade, offer an effective and efficient framework for reinforcement learning problems. However, their performances can often be unsatisfactory, suffering from unreliable reward improvements and slow convergence, due to high variance in gradient estimations. In this paper, we propose a universal reward profiling framework that can be seamlessly integrated with any policy gradient algorithm, where we selectively update the policy based on high-confidence performance estimations. We theoretically justify that our technique ",
      "summary_fr": "Policy gradient methods, which have been extensively studied in the last decade, offer an effective and efficient framework for reinforcement learning problems. However, their performances can often be unsatisfactory, suffering from unreliable reward improvements and slow convergence, due to high variance in gradient estimations. In this paper, we propose a universal reward profiling framework that can be seamlessly integrated with any policy gradient algorithm, where we selectively update the policy based on high-confidence performance estimations. We theoretically justify that our technique ",
      "resume_fr": "Policy gradient methods, which have been extensively studied in the last decade, offer an effective and efficient framework for reinforcement learning problems. However, their performances can often be unsatisfactory, suffering from unreliable reward improvements and slow convergence, due to high variance in gradient estimations. In this paper, we propose a universal reward profiling framework that can be seamlessly integrated with any policy gradient algorithm, where we selectively update the policy based on high-confidence performance estimations. We theoretically justify that our technique ",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "TimeViper: A Hybrid Mamba-Transformer Vision-Language Model for Efficient Long Video Understanding",
      "url": "https://arxiv.org/abs/2511.16595v1",
      "source": "arXiv – cs.CL (NLP/LLM)",
      "published": "2025-11-20T17:48:21.000Z",
      "score": 50,
      "summary_en": "We introduce TimeViper, a hybrid vision-language model designed to tackle challenges of long video understanding. Processing long videos demands both an efficient model architecture and an effective mechanism for handling extended temporal contexts. To this end, TimeViper adopts a hybrid Mamba-Transformer backbone that combines the efficiency of state-space models with the expressivity of attention mechanisms. Through this hybrid design, we reveal the vision-to-text information aggregation phenomenon, where information progressively flows from vision tokens to text tokens across increasing LLM",
      "summary_fr": "We introduce TimeViper, a hybrid vision-language model designed to tackle challenges of long video understanding. Processing long videos demands both an efficient model architecture and an effective mechanism for handling extended temporal contexts. To this end, TimeViper adopts a hybrid Mamba-Transformer backbone that combines the efficiency of state-space models with the expressivity of attention mechanisms. Through this hybrid design, we reveal the vision-to-text information aggregation phenomenon, where information progressively flows from vision tokens to text tokens across increasing LLM",
      "resume_fr": "We introduce TimeViper, a hybrid vision-language model designed to tackle challenges of long video understanding. Processing long videos demands both an efficient model architecture and an effective mechanism for handling extended temporal contexts. To this end, TimeViper adopts a hybrid Mamba-Transformer backbone that combines the efficiency of state-space models with the expressivity of attention mechanisms. Through this hybrid design, we reveal the vision-to-text information aggregation phenomenon, where information progressively flows from vision tokens to text tokens across increasing LLM",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 15,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=15, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "D-GARA: A Dynamic Benchmarking Framework for GUI Agent Robustness in Real-World Anomalies",
      "url": "https://arxiv.org/abs/2511.16590v1",
      "source": "arXiv – cs.CL (NLP/LLM)",
      "published": "2025-11-20T17:43:46.000Z",
      "score": 85,
      "summary_en": "Developing intelligent agents capable of operating a wide range of Graphical User Interfaces (GUIs) with human-level proficiency is a key milestone on the path toward Artificial General Intelligence. While most existing datasets and benchmarks for training and evaluating GUI agents are static and idealized, failing to reflect the complexity and unpredictability of real-world environments, particularly the presence of anomalies. To bridge this research gap, we propose D-GARA, a dynamic benchmarking framework, to evaluate Android GUI agent robustness in real-world anomalies. D-GARA introduces a ",
      "summary_fr": "Developing intelligent agents capable of operating a wide range of Graphical User Interfaces (GUIs) with human-level proficiency is a key milestone on the path toward Artificial General Intelligence. While most existing datasets and benchmarks for training and evaluating GUI agents are static and idealized, failing to reflect the complexity and unpredictability of real-world environments, particularly the presence of anomalies. To bridge this research gap, we propose D-GARA, a dynamic benchmarking framework, to evaluate Android GUI agent robustness in real-world anomalies. D-GARA introduces a ",
      "resume_fr": "Developing intelligent agents capable of operating a wide range of Graphical User Interfaces (GUIs) with human-level proficiency is a key milestone on the path toward Artificial General Intelligence. While most existing datasets and benchmarks for training and evaluating GUI agents are static and idealized, failing to reflect the complexity and unpredictability of real-world environments, particularly the presence of anomalies. To bridge this research gap, we propose D-GARA, a dynamic benchmarking framework, to evaluate Android GUI agent robustness in real-world anomalies. D-GARA introduces a ",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 15,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=15, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Artificial Intelligence and Accounting Research: A Framework and Agenda",
      "url": "https://arxiv.org/abs/2511.16055v1",
      "source": "arXiv – cs.AI + education/MOOC",
      "published": "2025-11-20T05:18:39.000Z",
      "score": 85,
      "summary_en": "Recent advances in artificial intelligence, particularly generative AI (GenAI) and large language models (LLMs), are fundamentally transforming accounting research, creating both opportunities and competitive threats for scholars. This paper proposes a framework that classifies AI-accounting research along two dimensions: research focus (accounting-centric versus AI-centric) and methodological approach (AI-based versus traditional methods). We apply this framework to papers from the IJAIS special issue and recent AI-accounting research published in leading accounting journals to map existing s",
      "summary_fr": "Recent advances in artificial intelligence, particularly generative AI (GenAI) and large language models (LLMs), are fundamentally transforming accounting research, creating both opportunities and competitive threats for scholars. This paper proposes a framework that classifies AI-accounting research along two dimensions: research focus (accounting-centric versus AI-centric) and methodological approach (AI-based versus traditional methods). We apply this framework to papers from the IJAIS special issue and recent AI-accounting research published in leading accounting journals to map existing s",
      "resume_fr": "Recent advances in artificial intelligence, particularly generative AI (GenAI) and large language models (LLMs), are fundamentally transforming accounting research, creating both opportunities and competitive threats for scholars. This paper proposes a framework that classifies AI-accounting research along two dimensions: research focus (accounting-centric versus AI-centric) and methodological approach (AI-based versus traditional methods). We apply this framework to papers from the IJAIS special issue and recent AI-accounting research published in leading accounting journals to map existing s",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Timing of reward cues alters the interaction between reward and interest on memory over time",
      "url": "https://www.nature.com/articles/s41539-025-00374-7",
      "source": "npj Science of Learning (Nature)",
      "published": "2025-11-20T00:00:00.000Z",
      "score": 70,
      "summary_en": "",
      "summary_fr": "",
      "resume_fr": "",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=0.",
      "image": "https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fs41539-025-00374-7/MediaObjects/41539_2025_374_Fig1_HTML.png"
    },
    {
      "title": "RescueLens: LLM-Powered Triage and Action on Volunteer Feedback for Food Rescue",
      "url": "https://arxiv.org/abs/2511.15698v1",
      "source": "arXiv – cs.LG + learning analytics",
      "published": "2025-11-19T18:55:16.000Z",
      "score": 70,
      "summary_en": "Food rescue organizations simultaneously tackle food insecurity and waste by working with volunteers to redistribute food from donors who have excess to recipients who need it. Volunteer feedback allows food rescue organizations to identify issues early and ensure volunteer satisfaction. However, food rescue organizations monitor feedback manually, which can be cumbersome and labor-intensive, making it difficult to prioritize which issues are most important. In this work, we investigate how large language models (LLMs) assist food rescue organizers in understanding and taking action based on v",
      "summary_fr": "Food rescue organizations simultaneously tackle food insecurity and waste by working with volunteers to redistribute food from donors who have excess to recipients who need it. Volunteer feedback allows food rescue organizations to identify issues early and ensure volunteer satisfaction. However, food rescue organizations monitor feedback manually, which can be cumbersome and labor-intensive, making it difficult to prioritize which issues are most important. In this work, we investigate how large language models (LLMs) assist food rescue organizers in understanding and taking action based on v",
      "resume_fr": "Food rescue organizations simultaneously tackle food insecurity and waste by working with volunteers to redistribute food from donors who have excess to recipients who need it. Volunteer feedback allows food rescue organizations to identify issues early and ensure volunteer satisfaction. However, food rescue organizations monitor feedback manually, which can be cumbersome and labor-intensive, making it difficult to prioritize which issues are most important. In this work, we investigate how large language models (LLMs) assist food rescue organizers in understanding and taking action based on v",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "The Impact of Quantization on Large Reasoning Model Reinforcement Learning",
      "url": "https://arxiv.org/abs/2511.15694v1",
      "source": "arXiv – cs.LG + learning analytics",
      "published": "2025-11-19T18:50:58.000Z",
      "score": 70,
      "summary_en": "Strong reasoning capabilities can now be achieved by large-scale reinforcement learning (RL) without any supervised fine-tuning. Although post-training quantization (PTQ) and quantization-aware training (QAT) are well studied in the context of fine-tuning, how quantization impacts RL in large reasoning models (LRMs) remains an open question. To answer this question, we conducted systematic experiments and discovered a significant gap in reasoning performance on mathematical benchmarks between post-RL quantized models and their quantization-aware RL optimized counterparts. Our findings suggest ",
      "summary_fr": "Strong reasoning capabilities can now be achieved by large-scale reinforcement learning (RL) without any supervised fine-tuning. Although post-training quantization (PTQ) and quantization-aware training (QAT) are well studied in the context of fine-tuning, how quantization impacts RL in large reasoning models (LRMs) remains an open question. To answer this question, we conducted systematic experiments and discovered a significant gap in reasoning performance on mathematical benchmarks between post-RL quantized models and their quantization-aware RL optimized counterparts. Our findings suggest ",
      "resume_fr": "Strong reasoning capabilities can now be achieved by large-scale reinforcement learning (RL) without any supervised fine-tuning. Although post-training quantization (PTQ) and quantization-aware training (QAT) are well studied in the context of fine-tuning, how quantization impacts RL in large reasoning models (LRMs) remains an open question. To answer this question, we conducted systematic experiments and discovered a significant gap in reasoning performance on mathematical benchmarks between post-RL quantized models and their quantization-aware RL optimized counterparts. Our findings suggest ",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Front-door Reducibility: Reducing ADMGs to the Standard Front-door Setting via a Graphical Criterion",
      "url": "https://arxiv.org/abs/2511.15679v1",
      "source": "arXiv – cs.LG + learning analytics",
      "published": "2025-11-19T18:26:55.000Z",
      "score": 70,
      "summary_en": "Front-door adjustment provides a simple closed-form identification formula under the classical front-door criterion, but its applicability is often viewed as narrow and strict. Although ID algorithm is very useful and is proved effective for causal relation identification in general causal graphs (if it is identifiable), performing ID algorithm does not guarantee to obtain a practical, easy-to-estimate interventional distribution expression. We argue that the applicability of the front-door criterion is not as limited as it seems: many more complicated causal graphs can be reduced to the front",
      "summary_fr": "Front-door adjustment provides a simple closed-form identification formula under the classical front-door criterion, but its applicability is often viewed as narrow and strict. Although ID algorithm is very useful and is proved effective for causal relation identification in general causal graphs (if it is identifiable), performing ID algorithm does not guarantee to obtain a practical, easy-to-estimate interventional distribution expression. We argue that the applicability of the front-door criterion is not as limited as it seems: many more complicated causal graphs can be reduced to the front",
      "resume_fr": "Front-door adjustment provides a simple closed-form identification formula under the classical front-door criterion, but its applicability is often viewed as narrow and strict. Although ID algorithm is very useful and is proved effective for causal relation identification in general causal graphs (if it is identifiable), performing ID algorithm does not guarantee to obtain a practical, easy-to-estimate interventional distribution expression. We argue that the applicability of the front-door criterion is not as limited as it seems: many more complicated causal graphs can be reduced to the front",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "SRPO: Self-Referential Policy Optimization for Vision-Language-Action Models",
      "url": "https://arxiv.org/abs/2511.15605v1",
      "source": "arXiv – cs.CL (NLP/LLM)",
      "published": "2025-11-19T16:52:23.000Z",
      "score": 70,
      "summary_en": "Vision-Language-Action (VLA) models excel in robotic manipulation but are constrained by their heavy reliance on expert demonstrations, leading to demonstration bias and limiting performance. Reinforcement learning (RL) is a vital post-training strategy to overcome these limits, yet current VLA-RL methods, including group-based optimization approaches, are crippled by severe reward sparsity. Relying on binary success indicators wastes valuable information in failed trajectories, resulting in low training efficiency. To solve this, we propose Self-Referential Policy Optimization (SRPO), a novel",
      "summary_fr": "Vision-Language-Action (VLA) models excel in robotic manipulation but are constrained by their heavy reliance on expert demonstrations, leading to demonstration bias and limiting performance. Reinforcement learning (RL) is a vital post-training strategy to overcome these limits, yet current VLA-RL methods, including group-based optimization approaches, are crippled by severe reward sparsity. Relying on binary success indicators wastes valuable information in failed trajectories, resulting in low training efficiency. To solve this, we propose Self-Referential Policy Optimization (SRPO), a novel",
      "resume_fr": "Vision-Language-Action (VLA) models excel in robotic manipulation but are constrained by their heavy reliance on expert demonstrations, leading to demonstration bias and limiting performance. Reinforcement learning (RL) is a vital post-training strategy to overcome these limits, yet current VLA-RL methods, including group-based optimization approaches, are crippled by severe reward sparsity. Relying on binary success indicators wastes valuable information in failed trajectories, resulting in low training efficiency. To solve this, we propose Self-Referential Policy Optimization (SRPO), a novel",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Keys to Building an AI University: A Framework from NVIDIA",
      "url": "https://content.knowledgehub.wiley.com/the-roadmap-to-becoming-an-ai-university-industry-brief/",
      "source": "IEEE Spectrum – AI",
      "published": "2025-11-19T16:00:16.000Z",
      "score": 85,
      "summary_en": "As artificial intelligence reshapes every industry, universities face a critical choice: lead the transformation or risk falling behind. The institutions that integrate AI across disciplines, invest in computing infrastructure, and conduct groundbreaking research will become destinations for top students, faculty, and research funding. This industry brief provides a practical roadmap for building a comprehensive AI strategy that drives enrollment, attracts research dollars, and delivers career-ready graduates. Download this free whitepaper now!",
      "summary_fr": "As artificial intelligence reshapes every industry, universities face a critical choice: lead the transformation or risk falling behind. The institutions that integrate AI across disciplines, invest in computing infrastructure, and conduct groundbreaking research will become destinations for top students, faculty, and research funding. This industry brief provides a practical roadmap for building a comprehensive AI strategy that drives enrollment, attracts research dollars, and delivers career-ready graduates. Download this free whitepaper now!",
      "resume_fr": "As artificial intelligence reshapes every industry, universities face a critical choice: lead the transformation or risk falling behind. The institutions that integrate AI across disciplines, invest in computing infrastructure, and conduct groundbreaking research will become destinations for top students, faculty, and research funding. This industry brief provides a practical roadmap for building a comprehensive AI strategy that drives enrollment, attracts research dollars, and delivers career-ready graduates. Download this free whitepaper now!",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=15.",
      "image": "https://content.knowledgehub.wiley.com/wp-content/uploads/2025/11/The-Roadmap-to-Becoming-an-AI-University-1500x400-1-500x133.jpg"
    },
    {
      "title": "PresentCoach: Dual-Agent Presentation Coaching through Exemplars and Interactive Feedback",
      "url": "https://arxiv.org/abs/2511.15253v1",
      "source": "arXiv – cs.HC + education",
      "published": "2025-11-19T09:15:21.000Z",
      "score": 85,
      "summary_en": "Effective presentation skills are essential in education, professional communication, and public speaking, yet learners often lack access to high-quality exemplars or personalized coaching. Existing AI tools typically provide isolated functionalities such as speech scoring or script generation without integrating reference modeling and interactive feedback into a cohesive learning experience. We introduce a dual-agent system that supports presentation practice through two complementary roles: the Ideal Presentation Agent and the Coach Agent. The Ideal Presentation Agent converts user-provided ",
      "summary_fr": "Effective presentation skills are essential in education, professional communication, and public speaking, yet learners often lack access to high-quality exemplars or personalized coaching. Existing AI tools typically provide isolated functionalities such as speech scoring or script generation without integrating reference modeling and interactive feedback into a cohesive learning experience. We introduce a dual-agent system that supports presentation practice through two complementary roles: the Ideal Presentation Agent and the Coach Agent. The Ideal Presentation Agent converts user-provided ",
      "resume_fr": "Effective presentation skills are essential in education, professional communication, and public speaking, yet learners often lack access to high-quality exemplars or personalized coaching. Existing AI tools typically provide isolated functionalities such as speech scoring or script generation without integrating reference modeling and interactive feedback into a cohesive learning experience. We introduce a dual-agent system that supports presentation practice through two complementary roles: the Ideal Presentation Agent and the Coach Agent. The Ideal Presentation Agent converts user-provided ",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Simulated Human Learning in a Dynamic, Partially-Observed, Time-Series Environment",
      "url": "https://arxiv.org/abs/2511.15032v1",
      "source": "arXiv – cs.HC + education",
      "published": "2025-11-19T01:57:52.000Z",
      "score": 65,
      "summary_en": "While intelligent tutoring systems (ITSs) can use information from past students to personalize instruction, each new student is unique. Moreover, the education problem is inherently difficult because the learning process is only partially observable. We therefore develop a dynamic, time-series environment to simulate a classroom setting, with student-teacher interventions - including tutoring sessions, lectures, and exams. In particular, we design the simulated environment to allow for varying levels of probing interventions that can gather more information. Then, we develop reinforcement lea",
      "summary_fr": "While intelligent tutoring systems (ITSs) can use information from past students to personalize instruction, each new student is unique. Moreover, the education problem is inherently difficult because the learning process is only partially observable. We therefore develop a dynamic, time-series environment to simulate a classroom setting, with student-teacher interventions - including tutoring sessions, lectures, and exams. In particular, we design the simulated environment to allow for varying levels of probing interventions that can gather more information. Then, we develop reinforcement lea",
      "resume_fr": "While intelligent tutoring systems (ITSs) can use information from past students to personalize instruction, each new student is unique. Moreover, the education problem is inherently difficult because the learning process is only partially observable. We therefore develop a dynamic, time-series environment to simulate a classroom setting, with student-teacher interventions - including tutoring sessions, lectures, and exams. In particular, we design the simulated environment to allow for varying levels of probing interventions that can gather more information. Then, we develop reinforcement lea",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 15,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=15, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "International perspectives on gaps and solutions for integrating research evidence into classroom practices",
      "url": "https://www.nature.com/articles/s41539-025-00370-x",
      "source": "npj Science of Learning (Nature)",
      "published": "2025-11-19T00:00:00.000Z",
      "score": 85,
      "summary_en": "",
      "summary_fr": "",
      "resume_fr": "",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=15.",
      "image": "https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fs41539-025-00370-x/MediaObjects/41539_2025_370_Fig1_HTML.png"
    },
    {
      "title": "Beyond Means: A Dynamic Framework for Predicting Customer Satisfaction",
      "url": "https://arxiv.org/abs/2511.14743v1",
      "source": "arXiv – cs.LG + learning analytics",
      "published": "2025-11-18T18:43:29.000Z",
      "score": 70,
      "summary_en": "Online ratings influence customer decision-making, yet standard aggregation methods, such as the sample mean, fail to adapt to quality changes over time and ignore review heterogeneity (e.g., review sentiment, a review's helpfulness). To address these challenges, we demonstrate the value of using the Gaussian process (GP) framework for rating aggregation. Specifically, we present a tailored GP model that captures the dynamics of ratings over time while additionally accounting for review heterogeneity. Based on 121,123 ratings from Yelp, we compare the predictive power of different rating aggre",
      "summary_fr": "Online ratings influence customer decision-making, yet standard aggregation methods, such as the sample mean, fail to adapt to quality changes over time and ignore review heterogeneity (e.g., review sentiment, a review's helpfulness). To address these challenges, we demonstrate the value of using the Gaussian process (GP) framework for rating aggregation. Specifically, we present a tailored GP model that captures the dynamics of ratings over time while additionally accounting for review heterogeneity. Based on 121,123 ratings from Yelp, we compare the predictive power of different rating aggre",
      "resume_fr": "Online ratings influence customer decision-making, yet standard aggregation methods, such as the sample mean, fail to adapt to quality changes over time and ignore review heterogeneity (e.g., review sentiment, a review's helpfulness). To address these challenges, we demonstrate the value of using the Gaussian process (GP) framework for rating aggregation. Specifically, we present a tailored GP model that captures the dynamics of ratings over time while additionally accounting for review heterogeneity. Based on 121,123 ratings from Yelp, we compare the predictive power of different rating aggre",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Strategic Innovation Management in the Age of Large Language Models Market Intelligence, Adaptive R&D, and Ethical Governance",
      "url": "https://arxiv.org/abs/2511.14709v1",
      "source": "arXiv – cs.CL (NLP/LLM)",
      "published": "2025-11-18T17:50:39.000Z",
      "score": 70,
      "summary_en": "This study analyzes the multiple functions of Large Language Models (LLMs) in transforming research and development (R&D) processes. By automating knowledge discovery, boosting hypothesis creation, integrating transdisciplinary insights, and enabling cooperation within innovation ecosystems, LLMs dramatically improve the efficiency and effectiveness of research processes. Through extensive analysis of scientific literature, patent databases, and experimental data, these models enable more flexible and informed R&D workflows, ultimately accelerating innovation cycles and lowering time-to-market",
      "summary_fr": "This study analyzes the multiple functions of Large Language Models (LLMs) in transforming research and development (R&D) processes. By automating knowledge discovery, boosting hypothesis creation, integrating transdisciplinary insights, and enabling cooperation within innovation ecosystems, LLMs dramatically improve the efficiency and effectiveness of research processes. Through extensive analysis of scientific literature, patent databases, and experimental data, these models enable more flexible and informed R&D workflows, ultimately accelerating innovation cycles and lowering time-to-market",
      "resume_fr": "This study analyzes the multiple functions of Large Language Models (LLMs) in transforming research and development (R&D) processes. By automating knowledge discovery, boosting hypothesis creation, integrating transdisciplinary insights, and enabling cooperation within innovation ecosystems, LLMs dramatically improve the efficiency and effectiveness of research processes. Through extensive analysis of scientific literature, patent databases, and experimental data, these models enable more flexible and informed R&D workflows, ultimately accelerating innovation cycles and lowering time-to-market",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Subword Tokenization Strategies for Kurdish Word Embeddings",
      "url": "https://arxiv.org/abs/2511.14696v1",
      "source": "arXiv – cs.CL (NLP/LLM)",
      "published": "2025-11-18T17:33:32.000Z",
      "score": 50,
      "summary_en": "We investigate tokenization strategies for Kurdish word embeddings by comparing word-level, morpheme-based, and BPE approaches on morphological similarity preservation tasks. We develop a BiLSTM-CRF morphological segmenter using bootstrapped training from minimal manual annotation and evaluate Word2Vec embeddings across comprehensive metrics including similarity preservation, clustering quality, and semantic organization. Our analysis reveals critical evaluation biases in tokenization comparison. While BPE initially appears superior in morphological similarity, it evaluates only 28.6\\% of test",
      "summary_fr": "We investigate tokenization strategies for Kurdish word embeddings by comparing word-level, morpheme-based, and BPE approaches on morphological similarity preservation tasks. We develop a BiLSTM-CRF morphological segmenter using bootstrapped training from minimal manual annotation and evaluate Word2Vec embeddings across comprehensive metrics including similarity preservation, clustering quality, and semantic organization. Our analysis reveals critical evaluation biases in tokenization comparison. While BPE initially appears superior in morphological similarity, it evaluates only 28.6\\% of test",
      "resume_fr": "We investigate tokenization strategies for Kurdish word embeddings by comparing word-level, morpheme-based, and BPE approaches on morphological similarity preservation tasks. We develop a BiLSTM-CRF morphological segmenter using bootstrapped training from minimal manual annotation and evaluate Word2Vec embeddings across comprehensive metrics including similarity preservation, clustering quality, and semantic organization. Our analysis reveals critical evaluation biases in tokenization comparison. While BPE initially appears superior in morphological similarity, it evaluates only 28.6\\% of test",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 15,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=15, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Talk, Snap, Complain: Validation-Aware Multimodal Expert Framework for Fine-Grained Customer Grievances",
      "url": "https://arxiv.org/abs/2511.14693v1",
      "source": "arXiv – cs.CL (NLP/LLM)",
      "published": "2025-11-18T17:29:28.000Z",
      "score": 70,
      "summary_en": "Existing approaches to complaint analysis largely rely on unimodal, short-form content such as tweets or product reviews. This work advances the field by leveraging multimodal, multi-turn customer support dialogues, where users often share both textual complaints and visual evidence (e.g., screenshots, product photos) to enable fine-grained classification of complaint aspects and severity. We introduce VALOR, a Validation-Aware Learner with Expert Routing, tailored for this multimodal setting. It employs a multi-expert reasoning setup using large-scale generative models with Chain-of-Thought (",
      "summary_fr": "Existing approaches to complaint analysis largely rely on unimodal, short-form content such as tweets or product reviews. This work advances the field by leveraging multimodal, multi-turn customer support dialogues, where users often share both textual complaints and visual evidence (e.g., screenshots, product photos) to enable fine-grained classification of complaint aspects and severity. We introduce VALOR, a Validation-Aware Learner with Expert Routing, tailored for this multimodal setting. It employs a multi-expert reasoning setup using large-scale generative models with Chain-of-Thought (",
      "resume_fr": "Existing approaches to complaint analysis largely rely on unimodal, short-form content such as tweets or product reviews. This work advances the field by leveraging multimodal, multi-turn customer support dialogues, where users often share both textual complaints and visual evidence (e.g., screenshots, product photos) to enable fine-grained classification of complaint aspects and severity. We introduce VALOR, a Validation-Aware Learner with Expert Routing, tailored for this multimodal setting. It employs a multi-expert reasoning setup using large-scale generative models with Chain-of-Thought (",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Encoding and Understanding Astrophysical Information in Large Language Model-Generated Summaries",
      "url": "https://arxiv.org/abs/2511.14685v1",
      "source": "arXiv – cs.CL (NLP/LLM)",
      "published": "2025-11-18T17:23:29.000Z",
      "score": 50,
      "summary_en": "Large Language Models have demonstrated the ability to generalize well at many levels across domains, modalities, and even shown in-context learning capabilities. This enables research questions regarding how they can be used to encode physical information that is usually only available from scientific measurements, and loosely encoded in textual descriptions. Using astrophysics as a test bed, we investigate if LLM embeddings can codify physical summary statistics that are obtained from scientific measurements through two main questions: 1) Does prompting play a role on how those quantities ar",
      "summary_fr": "Large Language Models have demonstrated the ability to generalize well at many levels across domains, modalities, and even shown in-context learning capabilities. This enables research questions regarding how they can be used to encode physical information that is usually only available from scientific measurements, and loosely encoded in textual descriptions. Using astrophysics as a test bed, we investigate if LLM embeddings can codify physical summary statistics that are obtained from scientific measurements through two main questions: 1) Does prompting play a role on how those quantities ar",
      "resume_fr": "Large Language Models have demonstrated the ability to generalize well at many levels across domains, modalities, and even shown in-context learning capabilities. This enables research questions regarding how they can be used to encode physical information that is usually only available from scientific measurements, and loosely encoded in textual descriptions. Using astrophysics as a test bed, we investigate if LLM embeddings can codify physical summary statistics that are obtained from scientific measurements through two main questions: 1) Does prompting play a role on how those quantities ar",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 15,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=15, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Quadratic Term Correction on Heaps' Law",
      "url": "https://arxiv.org/abs/2511.14683v1",
      "source": "arXiv – cs.CL (NLP/LLM)",
      "published": "2025-11-18T17:22:00.000Z",
      "score": 70,
      "summary_en": "Heaps' or Herdan's law characterizes the word-type vs. word-token relation by a power-law function, which is concave in linear-linear scale but a straight line in log-log scale. However, it has been observed that even in log-log scale, the type-token curve is still slightly concave, invalidating the power-law relation. At the next-order approximation, we have shown, by twenty English novels or writings (some are translated from another language to English), that quadratic functions in log-log scale fit the type-token data perfectly. Regression analyses of log(type)-log(token) data with both a ",
      "summary_fr": "Heaps' or Herdan's law characterizes the word-type vs. word-token relation by a power-law function, which is concave in linear-linear scale but a straight line in log-log scale. However, it has been observed that even in log-log scale, the type-token curve is still slightly concave, invalidating the power-law relation. At the next-order approximation, we have shown, by twenty English novels or writings (some are translated from another language to English), that quadratic functions in log-log scale fit the type-token data perfectly. Regression analyses of log(type)-log(token) data with both a ",
      "resume_fr": "Heaps' or Herdan's law characterizes the word-type vs. word-token relation by a power-law function, which is concave in linear-linear scale but a straight line in log-log scale. However, it has been observed that even in log-log scale, the type-token curve is still slightly concave, invalidating the power-law relation. At the next-order approximation, we have shown, by twenty English novels or writings (some are translated from another language to English), that quadratic functions in log-log scale fit the type-token data perfectly. Regression analyses of log(type)-log(token) data with both a ",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Making Evidence Actionable in Adaptive Learning",
      "url": "https://arxiv.org/abs/2511.14052v1",
      "source": "arXiv – cs.AI + education/MOOC",
      "published": "2025-11-18T02:06:08.000Z",
      "score": 85,
      "summary_en": "Adaptive learning often diagnoses precisely yet intervenes weakly, yielding help that is mistimed or misaligned. This study presents evidence supporting an instructor-governed feedback loop that converts concept-level assessment evidence into vetted micro-interventions. The adaptive learning algorithm contains three safeguards: adequacy as a hard guarantee of gap closure, attention as a budgeted constraint for time and redundancy, and diversity as protection against overfitting to a single resource. We formalize intervention assignment as a binary integer program with constraints for coverage,",
      "summary_fr": "Adaptive learning often diagnoses precisely yet intervenes weakly, yielding help that is mistimed or misaligned. This study presents evidence supporting an instructor-governed feedback loop that converts concept-level assessment evidence into vetted micro-interventions. The adaptive learning algorithm contains three safeguards: adequacy as a hard guarantee of gap closure, attention as a budgeted constraint for time and redundancy, and diversity as protection against overfitting to a single resource. We formalize intervention assignment as a binary integer program with constraints for coverage,",
      "resume_fr": "Adaptive learning often diagnoses precisely yet intervenes weakly, yielding help that is mistimed or misaligned. This study presents evidence supporting an instructor-governed feedback loop that converts concept-level assessment evidence into vetted micro-interventions. The adaptive learning algorithm contains three safeguards: adequacy as a hard guarantee of gap closure, attention as a budgeted constraint for time and redundancy, and diversity as protection against overfitting to a single resource. We formalize intervention assignment as a binary integer program with constraints for coverage,",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Exploring the Use of ChatGPT by Computer Science Students in Software Development: Applications, Ethical Considerations, and Insights for Engineering Education",
      "url": "https://arxiv.org/abs/2511.13996v1",
      "source": "arXiv – cs.HC + education",
      "published": "2025-11-17T23:54:08.000Z",
      "score": 85,
      "summary_en": "ChatGPT has been increasingly used in computer science, offering efficient support across software development tasks. While it helps students navigate programming challenges, its use also raises concerns about academic integrity and overreliance. Despite growing interest in this topic, prior research has largely relied on surveys, emphasizing trends over in-depth analysis of students' strategies and ethical awareness. This study complements existing work through a qualitative investigation of how computer science students in one UK institution strategically and ethically engage with ChatGPT in",
      "summary_fr": "ChatGPT has been increasingly used in computer science, offering efficient support across software development tasks. While it helps students navigate programming challenges, its use also raises concerns about academic integrity and overreliance. Despite growing interest in this topic, prior research has largely relied on surveys, emphasizing trends over in-depth analysis of students' strategies and ethical awareness. This study complements existing work through a qualitative investigation of how computer science students in one UK institution strategically and ethically engage with ChatGPT in",
      "resume_fr": "ChatGPT has been increasingly used in computer science, offering efficient support across software development tasks. While it helps students navigate programming challenges, its use also raises concerns about academic integrity and overreliance. Despite growing interest in this topic, prior research has largely relied on surveys, emphasizing trends over in-depth analysis of students' strategies and ethical awareness. This study complements existing work through a qualitative investigation of how computer science students in one UK institution strategically and ethically engage with ChatGPT in",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "ST-ProC: A Graph-Prototypical Framework for Robust Semi-Supervised Travel Mode Identification",
      "url": "https://arxiv.org/abs/2511.13702v1",
      "source": "arXiv – cs.LG + learning analytics",
      "published": "2025-11-17T18:52:11.000Z",
      "score": 70,
      "resume_fr": "Travel mode identification (TMI) from GPS trajectories is critical for urban intelligence, but is hampered by the high cost of annotation, leading to severe label scarcity. Prevailing semi-supervised learning (SSL) methods are ill-suited for this task, as they suffer from catastrophic confirmation bias and ignore the intrinsic data manifold. We propose ST-ProC, a novel graph-prototypical multi-objective SSL framework to address these limitations. Our framework synergizes a graph-prototypical core with foundational SSL Support. The core exploits the data manifold via graph regularization, proto",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=0.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Making Evidence Actionable in Adaptive Learning Closing the Diagnostic Pedagogical Loop",
      "url": "https://arxiv.org/abs/2511.13542v1",
      "source": "arXiv – cs.AI + education/MOOC",
      "published": "2025-11-17T16:15:50.000Z",
      "score": 85,
      "summary_en": "Adaptive learning often diagnoses precisely yet intervenes weakly, producing help that is mistimed or misaligned. This study presents evidence supporting an instructor-governed feedback loop that converts concept-level assessment evidence into vetted microinterventions. The adaptive learning algorithm includes three safeguards: adequacy as a hard guarantee of gap closure, attention as a budgeted limit for time and redundancy, and diversity as protection against overfitting to a single resource. We formulate intervention assignment as a binary integer program with constraints for coverage, time",
      "summary_fr": "Adaptive learning often diagnoses precisely yet intervenes weakly, producing help that is mistimed or misaligned. This study presents evidence supporting an instructor-governed feedback loop that converts concept-level assessment evidence into vetted microinterventions. The adaptive learning algorithm includes three safeguards: adequacy as a hard guarantee of gap closure, attention as a budgeted limit for time and redundancy, and diversity as protection against overfitting to a single resource. We formulate intervention assignment as a binary integer program with constraints for coverage, time",
      "resume_fr": "Adaptive learning often diagnoses precisely yet intervenes weakly, producing help that is mistimed or misaligned. This study presents evidence supporting an instructor-governed feedback loop that converts concept-level assessment evidence into vetted microinterventions. The adaptive learning algorithm includes three safeguards: adequacy as a hard guarantee of gap closure, attention as a budgeted limit for time and redundancy, and diversity as protection against overfitting to a single resource. We formulate intervention assignment as a binary integer program with constraints for coverage, time",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "The Quick Red Fox gets the best Data Driven Classroom Interviews: A manual for an interview app and its associated methodology",
      "url": "https://arxiv.org/abs/2511.13466v1",
      "source": "arXiv – cs.HC + education",
      "published": "2025-11-17T15:08:47.000Z",
      "score": 50,
      "resume_fr": "Data Driven Classroom Interviews (DDCIs) are an interviewing technique that is facilitated by recent technological developments in the learning analytics community. DDCIs are short, targeted interviews that allow researchers to contextualize students' interactions with a digital learning environment (e.g., intelligent tutoring systems or educational games) while minimizing the amount of time that the researcher interrupts that learning experience, and focusing researcher time on the events they most want to focus on DDCIs are facilitated by a research tool called the Quick Red Fox (QRF)--an op",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Examining the Usage of Generative AI Models in Student Learning Activities for Software Programming",
      "url": "https://arxiv.org/abs/2511.13271v1",
      "source": "arXiv – cs.AI + education/MOOC",
      "published": "2025-11-17T11:42:24.000Z",
      "score": 100,
      "summary_en": "The rise of Generative AI (GenAI) tools like ChatGPT has created new opportunities and challenges for computing education. Existing research has primarily focused on GenAI's ability to complete educational tasks and its impact on student performance, often overlooking its effects on knowledge gains. In this study, we investigate how GenAI assistance compares to conventional online resources in supporting knowledge gains across different proficiency levels. We conducted a controlled user experiment with 24 undergraduate students of two different levels of programming experience (beginner, inter",
      "summary_fr": "The rise of Generative AI (GenAI) tools like ChatGPT has created new opportunities and challenges for computing education. Existing research has primarily focused on GenAI's ability to complete educational tasks and its impact on student performance, often overlooking its effects on knowledge gains. In this study, we investigate how GenAI assistance compares to conventional online resources in supporting knowledge gains across different proficiency levels. We conducted a controlled user experiment with 24 undergraduate students of two different levels of programming experience (beginner, inter",
      "resume_fr": "The rise of Generative AI (GenAI) tools like ChatGPT has created new opportunities and challenges for computing education. Existing research has primarily focused on GenAI's ability to complete educational tasks and its impact on student performance, often overlooking its effects on knowledge gains. In this study, we investigate how GenAI assistance compares to conventional online resources in supporting knowledge gains across different proficiency levels. We conducted a controlled user experiment with 24 undergraduate students of two different levels of programming experience (beginner, inter",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 15,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=15, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "SynthGuard: An Open Platform for Detecting AI-Generated Multimedia with Multimodal LLMs",
      "url": "https://arxiv.org/abs/2511.12404v1",
      "source": "arXiv – cs.AI + education/MOOC",
      "published": "2025-11-16T00:50:24.000Z",
      "score": 50,
      "resume_fr": "Artificial Intelligence (AI) has made it possible for anyone to create images, audio, and video with unprecedented ease, enriching education, communication, and creative expression. At the same time, the rapid rise of AI-generated media has introduced serious risks, including misinformation, identity misuse, and the erosion of public trust as synthetic content becomes increasingly indistinguishable from real media. Although deepfake detection has advanced, many existing tools remain closed-source, limited in modality, or lacking transparency and educational value, making it difficult for users",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Students Compete—and Cooperate—in FIRST Global Robotics Challenge",
      "url": "https://spectrum.ieee.org/first-global-robotics-challenge",
      "source": "IEEE Spectrum – AI",
      "published": "2025-11-15T14:00:02.000Z",
      "score": 50,
      "resume_fr": "Aspiring engineers from 191 countries gathered in Panama City in October to compete in the FIRST Global Robotics Challenge. The annual contest aims to foster problem-solving, cooperation, and inspire the next generation of engineers through three challenges that are inspired by a different theme every year. Teams of students from 14 to 18 years old from around the world compete in the three day event, remotely operating their robots to complete the challenges. This year’s topic was “Eco-equilibrium,” emphasizing the importance of preserving ecosystems and protecting vulnerable species. Turning",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=0, Impact=15.",
      "image": "https://spectrum.ieee.org/media-library/image.jpg?id=62186165&width=1200&height=600&coordinates=0%2C232%2C0%2C232"
    },
    {
      "title": "CollaClassroom: An AI-Augmented Collaborative Learning Platform with LLM Support in the Context of Bangladeshi University Students",
      "url": "https://arxiv.org/abs/2511.11823v1",
      "source": "arXiv – cs.HC + education",
      "published": "2025-11-14T19:23:42.000Z",
      "score": 50,
      "resume_fr": "CollaClassroom is an AI-enhanced platform that embeds large language models (LLMs) into both individual and group study panels to support real-time collaboration. We evaluate CollaClassroom with Bangladeshi university students (N = 12) through a small-group study session and a pre-post survey. Participants have substantial prior experience with collaborative learning and LLMs and express strong receptivity to LLM-assisted study (92% agree/strongly agree). Usability ratings are positive, including high learnability(67% \"easy\"), strong reliability (83% \"reliable\"), and low frustration (83% \"not ",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Differences in the Moral Foundations of Large Language Models",
      "url": "https://arxiv.org/abs/2511.11790v1",
      "source": "arXiv – cs.AI + education/MOOC",
      "published": "2025-11-14T18:21:22.000Z",
      "score": 50,
      "resume_fr": "Large language models are increasingly being used in critical domains of politics, business, and education, but the nature of their normative ethical judgment remains opaque. Alignment research has, to date, not sufficiently utilized perspectives and insights from the field of moral psychology to inform training and evaluation of frontier models. I perform a synthetic experiment on a wide range of models from most major model providers using Jonathan Haidt's influential moral foundations theory (MFT) to elicit diverse value judgments from LLMs. Using multiple descriptive statistical approaches",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 0,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=0, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Exploring The Interaction-Outcome Paradox: Seemingly Richer and More Self-Aware Interactions with LLMs May Not Yet Lead to Better Learning",
      "url": "https://arxiv.org/abs/2511.09458v1",
      "source": "arXiv – cs.HC + education",
      "published": "2025-11-12T16:18:36.000Z",
      "score": 85,
      "resume_fr": "While Large Language Models (LLMs) have transformed the user interface for learning, moving from keyword search to natural language dialogue, their impact on educational outcomes remains unclear. We present a controlled study (N=20) that directly compares the learning interaction and outcomes between LLM and search-based interfaces. We found that although LLMs elicit richer and nuanced interactions from a learner, they do not produce broadly better learning outcomes. In this paper, we explore this the ``Interaction-Outcome Paradox.'' To explain this, we discuss the concept of a cognitive shift",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=15.",
      "image": "https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "title": "Densing law of LLMs",
      "url": "https://www.nature.com/articles/s42256-025-01137-0",
      "source": "Nature Machine Intelligence",
      "published": "2025-11-06T00:00:00.000Z",
      "score": 70,
      "summary_en": "",
      "summary_fr": "",
      "resume_fr": "",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 0,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=0, Impact=0.",
      "image": "https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fs42256-025-01137-0/MediaObjects/42256_2025_1137_Fig1_HTML.png"
    },
    {
      "title": "Interpersonal neural synchronization underlies interactive concept learning in older adults",
      "url": "https://www.nature.com/articles/s41539-025-00368-5",
      "source": "npj Science of Learning (Nature)",
      "published": "2025-10-31T00:00:00.000Z",
      "score": 85,
      "summary_en": "",
      "summary_fr": "",
      "resume_fr": "",
      "tags": [],
      "breakdown": {
        "research": 35,
        "policy": 35,
        "institution": 15,
        "impact": 0
      },
      "reason": "Heuristique: Recherche=35, Politiques=35, Institution=15, Impact=0.",
      "image": "https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fs41539-025-00368-5/MediaObjects/41539_2025_368_Fig1_HTML.png"
    },
    {
      "title": "How to avoid three common pitfalls in EdTech impact evaluations",
      "url": "https://world-education-blog.org/2025/10/17/how-to-avoid-three-common-pitfalls-in-edtech-impact-evaluations/",
      "source": "UNESCO GEM – World Education Blog",
      "published": "2025-10-17T09:56:32.000Z",
      "score": 65,
      "summary_en": "Professor Natalia I. Kucirkova, Professor of Early Childhood Development at the University of Stavanger, Norway, and The Open University, UK Around the world, major philanthropic agencies are turning to educational technology (EdTech) to improve learning. In the rush to identify tools that can quickly, cost-effectively, and reliably support children’s learning, ‘impact’ has become the central […] The post How to avoid three common pitfalls in EdTech impact evaluations appeared first on World Education Blog.",
      "summary_fr": "Professor Natalia I. Kucirkova, Professor of Early Childhood Development at the University of Stavanger, Norway, and The Open University, UK Around the world, major philanthropic agencies are turning to educational technology (EdTech) to improve learning. In the rush to identify tools that can quickly, cost-effectively, and reliably support children’s learning, ‘impact’ has become the central […] The post How to avoid three common pitfalls in EdTech impact evaluations appeared first on World Education Blog.",
      "resume_fr": "Professor Natalia I. Kucirkova, Professor of Early Childhood Development at the University of Stavanger, Norway, and The Open University, UK Around the world, major philanthropic agencies are turning to educational technology (EdTech) to improve learning. In the rush to identify tools that can quickly, cost-effectively, and reliably support children’s learning, ‘impact’ has become the central […] The post How to avoid three common pitfalls in EdTech impact evaluations appeared first on World Education Blog.",
      "tags": [],
      "breakdown": {
        "research": 0,
        "policy": 35,
        "institution": 15,
        "impact": 15
      },
      "reason": "Heuristique: Recherche=0, Politiques=35, Institution=15, Impact=15.",
      "image": "https://world-education-blog.org/wp-content/uploads/2025/10/Untitled-Twitter-Post6.png"
    }
  ]
}